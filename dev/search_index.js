var documenterSearchIndex = {"docs":
[{"location":"reference/advanced/size/#Size-Strategies","page":"Size Strategies","title":"Size Strategies","text":"","category":"section"},{"location":"reference/advanced/size/","page":"Size Strategies","title":"Size Strategies","text":"As shown in Advanced Tutorial size strategies give a high degree of flexibility when it comes to changing the size of vertices in the graph.","category":"page"},{"location":"reference/advanced/size/","page":"Size Strategies","title":"Size Strategies","text":"All size strategies are executed through the Δsize! function.","category":"page"},{"location":"reference/advanced/size/","page":"Size Strategies","title":"Size Strategies","text":"Imported to namespace by","category":"page"},{"location":"reference/advanced/size/","page":"Size Strategies","title":"Size Strategies","text":"using NaiveNASlib.Advanced","category":"page"},{"location":"reference/advanced/size/#NaiveNASlib.DefaultJuMPΔSizeStrategy","page":"Size Strategies","title":"NaiveNASlib.DefaultJuMPΔSizeStrategy","text":"DefaultJuMPΔSizeStrategy <: AbstractJuMPΔSizeStrategy\nDefaultJuMPΔSizeStrategy()\n\nDefault strategy which applies default constraints or objectives to a model. \n\nIntended use is for strategies which apply special constraints or objectives to a subset of the vertices.\n\nAlso useful when configuring DecoratingJuMPΔSizeStrategies.\n\nExamples\n\nUse to get add special constraints for a subset of vertices:\n\nfunction NaiveNASlib.addsomeconstraint!(s::MySpecialStrategy, v::AbstractVertex, data)\n    if v === s.targetvertex\n        # Add some special constraints here\n    else\n        # Use the default\n        NaiveNASlib.addsomeconstraint!(DefaultJuMPΔSizeStrategy(), v::AbstractVertex, data)\n    end\nend\n\nUse with a DecoratingJuMPΔSizeStrategy:\n\njulia> using NaiveNASlib, NaiveNASlib.Advanced\n\njulia> WithUtilityFun(defaultutility, DefaultJuMPΔSizeStrategy())\nWithUtilityFun{typeof(defaultutility), DefaultJuMPΔSizeStrategy}(NaiveNASlib.defaultutility, DefaultJuMPΔSizeStrategy())\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.ΔNinExact","page":"Size Strategies","title":"NaiveNASlib.ΔNinExact","text":"ΔNinExact(args...; fallback)\n\nReturn a ΔNout{Exact} configured to set nout of the inputs to vertices in args to the given sizes.\n\nFor vertices with more than one input, the size change must be expressed as a tuple with one element per input.  Use missing to indicate that no special treatment is needed for an input.\n\nAccepts either a Dict or arguments used to create a Dict (e.g. a set of Pairs or a generator).\n\nBy default, fallback is set to give a warning and then try again with ΔNinRelaxed(args...).\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend, NaiveNASlib.Advanced\n\njulia> module TestNNLib\n           using NaiveNASlib, NaiveNASlib.Extend\n           mutable struct Affine{T} W::Matrix{T} end\n           NaiveNASlib.nout(a::Affine) = size(a.W, 1)\n           NaiveNASlib.nin(a::Affine) = [size(a.W, 2)]\n           NaiveNASlib.Δsize!(a::Affine, ins::AbstractVector, outs::AbstractVector) = a.W = parselect(a.W, 2=>ins[1], 1=>outs)\n           affine(in, outsize) = absorbvertex(Affine(ones(outsize, nout(in))), in)\n           export affine\n       end;\n\njulia> using .TestNNLib;\n\njulia> iv = affine(inputvertex(\"in\", 3), 6);\n\njulia> v1 = affine(iv, 4);\n\njulia> v2 = affine(iv, 5);\n\njulia> ΔNinExact(v1, 3);\n\njulia> ΔNinExact(v1 => -3, v2 => -2);\n\njulia> ΔNinExact(Dict(v1 => 3, v2 => 2));\n\njulia> v3 = conc(affine(iv, 4), affine(iv, 5), affine(iv, 6); dims=2);\n\njulia> v4 = conc(affine(iv, 7), affine(iv, 8); dims=2);\n\njulia> ΔNinExact(v3, 3, missing, 2);\n\njulia> ΔNinExact(v3 => (3, missing, 2), v4 => (-2, 0));\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/size/#NaiveNASlib.ΔNinRelaxed","page":"Size Strategies","title":"NaiveNASlib.ΔNinRelaxed","text":"ΔNinRelaxed(args...; fallback)\n\nSame as ΔNinExact except Exact is replaced by Relaxed and fallback set to ΔSizeFailNoOp by default.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend, NaiveNASlib.Advanced\n\njulia> module TestNNLib\n           using NaiveNASlib, NaiveNASlib.Extend\n           mutable struct Affine{T} W::Matrix{T} end\n           NaiveNASlib.nout(a::Affine) = size(a.W, 1)\n           NaiveNASlib.nin(a::Affine) = [size(a.W, 2)]\n           NaiveNASlib.Δsize!(a::Affine, ins::AbstractVector, outs::AbstractVector) = a.W = parselect(a.W, 2=>ins[1], 1=>outs)\n           affine(in, outsize) = absorbvertex(Affine(ones(outsize, nout(in))), in)\n           export affine\n       end;\n\njulia> using .TestNNLib;\n\njulia> iv = affine(inputvertex(\"in\", 3), 6);\n\njulia> v1 = affine(iv, 4);\n\njulia> v2 = affine(iv, 5);\n\njulia> ΔNinRelaxed(v1, 3);\n\njulia> ΔNinRelaxed(v1 => -3, v2 => -2);\n\njulia> ΔNinRelaxed(Dict(v1 => 3, v2 => 2));\n\njulia> v3 = conc(affine(iv, 4), affine(iv, 5), affine(iv, 6); dims=2);\n\njulia> v4 = conc(affine(iv, 7), affine(iv, 8); dims=2);\n\njulia> ΔNinRelaxed(v3, 3, missing, 2);\n\njulia> ΔNinRelaxed(v3 => (3, missing, 2), v4 => (-2, 0));\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/size/#NaiveNASlib.ΔNin","page":"Size Strategies","title":"NaiveNASlib.ΔNin","text":"ΔNin(args...;[fallback])\n\nSplits args into relaxed and exact size changes and creates the appropriate strategy (one of ΔNout{Exact}, ΔNout{Relaxed} or ΔNoutMix).\n\nFallback strategy may be supplied through the fallback keyword. Defaults to ΔNinRelaxed for all given vertices.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend, NaiveNASlib.Advanced\n\njulia> module TestNNLib\n           using NaiveNASlib, NaiveNASlib.Extend\n           mutable struct Affine{T} W::Matrix{T} end\n           NaiveNASlib.nout(a::Affine) = size(a.W, 1)\n           NaiveNASlib.nin(a::Affine) = [size(a.W, 2)]\n           NaiveNASlib.Δsize!(a::Affine, ins::AbstractVector, outs::AbstractVector) = a.W = parselect(a.W, 2=>ins[1], 1=>outs)\n           affine(in, outsize) = absorbvertex(Affine(ones(outsize, nout(in))), in)\n           export affine\n       end;\n\njulia> using .TestNNLib;\n\njulia> iv = affine(inputvertex(\"in\", 3), 6);\n\njulia> v1 = affine(iv, 4);\n\njulia> v2 = affine(iv, 5);\n\njulia> ΔNin(v1, 3);\n\njulia> ΔNin(v1 => -3, v2 => -2);\n\njulia> ΔNin(Dict(v1 => 3, v2 => 2));\n\njulia> v3 = conc(affine(iv, 4), affine(iv, 5), affine(iv, 6); dims=2);\n\njulia> v4 = conc(affine(iv, 7), affine(iv, 8); dims=2);\n\njulia> ΔNin(v3, 3, missing, 2);\n\njulia> ΔNin(v3 => (3, missing, 2), v4 => (-2, 0));\n\njulia> ΔNin(v3, relaxed(3), missing, 2);\n\njulia> ΔNin(v3 => (relaxed(3), missing, 2), v4 => relaxed(-2, 0));\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/size/#NaiveNASlib.ΔNoutExact","page":"Size Strategies","title":"NaiveNASlib.ΔNoutExact","text":"ΔNoutExact(args...; fallback)\n\nReturn a ΔNout{Exact} with fallback set to give a warning and then try again with ΔNoutRelaxed(args...).\n\nAccepts either a Dict or arguments used to create a Dict (e.g. a set of Pairs or a generator).\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend, NaiveNASlib.Advanced\n\njulia> module TestNNLib\n           using NaiveNASlib, NaiveNASlib.Extend\n           mutable struct Affine{T} W::Matrix{T} end\n           NaiveNASlib.nout(a::Affine) = size(a.W, 1)\n           NaiveNASlib.nin(a::Affine) = [size(a.W, 2)]\n           NaiveNASlib.Δsize!(a::Affine, ins::AbstractVector, outs::AbstractVector) = a.W = parselect(a.W, 2=>ins[1], 1=>outs)\n           affine(in, outsize) = absorbvertex(Affine(ones(outsize, nout(in))), in)\n           export affine\n       end;\n\njulia> using .TestNNLib;\n\njulia> iv = affine(inputvertex(\"in\", 3), 6);\n\njulia> v1 = affine(iv, 4);\n\njulia> v2 = affine(iv, 5);\n\njulia> ΔNoutExact(v1, 3);\n\njulia> ΔNoutExact(v1 => -3, v2 => -2);\n\njulia> ΔNoutExact(Dict(v1 => 3, v2 => 2));\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/size/#NaiveNASlib.ΔNoutRelaxed","page":"Size Strategies","title":"NaiveNASlib.ΔNoutRelaxed","text":"ΔNoutRelaxed(args...;fallback)\n\nReturn a ΔNout{Relaxed} with fallback set to ΔSizeFailNoOp.\n\nAccepts either a Dict or arguments used to create a Dict (e.g. a set of Pairs or a generator).\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend, NaiveNASlib.Advanced\n\njulia> module TestNNLib\n           using NaiveNASlib, NaiveNASlib.Extend\n           mutable struct Affine{T} W::Matrix{T} end\n           NaiveNASlib.nout(a::Affine) = size(a.W, 1)\n           NaiveNASlib.nin(a::Affine) = [size(a.W, 2)]\n           NaiveNASlib.Δsize!(a::Affine, ins::AbstractVector, outs::AbstractVector) = a.W = parselect(a.W, 2=>ins[1], 1=>outs)\n           affine(in, outsize) = absorbvertex(Affine(ones(outsize, nout(in))), in)\n           export affine\n       end;\n\njulia> using .TestNNLib;\n\njulia> iv = affine(inputvertex(\"in\", 3), 6);\n\njulia> v1 = affine(iv, 4);\n\njulia> v2 = affine(iv, 5);\n\njulia> ΔNoutRelaxed(v1, 3);\n\njulia> ΔNoutRelaxed(v1 => -3, v2 => -2);\n\njulia> ΔNoutRelaxed(Dict(v1 => 3, v2 => 2));\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/size/#NaiveNASlib.ΔNout-Tuple","page":"Size Strategies","title":"NaiveNASlib.ΔNout","text":"ΔNout(args...;[fallback])\n\nSplits args into relaxed and exact size changes and creates the appropriate strategy (one of ΔNout{Exact}, ΔNout{Relaxed} or ΔNoutMix).\n\nFallback strategy may be supplied through the fallback keyword. Defaults to ΔNoutRelaxed for all given vertices.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend, NaiveNASlib.Advanced\n\njulia> module TestNNLib\n           using NaiveNASlib, NaiveNASlib.Extend\n           mutable struct Affine{T} W::Matrix{T} end\n           NaiveNASlib.nout(a::Affine) = size(a.W, 1)\n           NaiveNASlib.nin(a::Affine) = [size(a.W, 2)]\n           NaiveNASlib.Δsize!(a::Affine, ins::AbstractVector, outs::AbstractVector) = a.W = parselect(a.W, 2=>ins[1], 1=>outs)\n           affine(in, outsize) = absorbvertex(Affine(ones(outsize, nout(in))), in)\n           export affine\n       end;\n\njulia> using .TestNNLib;\n\njulia> iv = affine(inputvertex(\"in\", 3), 6);\n\njulia> v1 = affine(iv, 4);\n\njulia> v2 = affine(iv, 5);\n\njulia> ΔNout(v1, 3);\n\njulia> ΔNout(v1 => -3, v2 => -2);\n\njulia> ΔNout(Dict(v1 => 3, v2 => 2));\n\njulia> ΔNout(v1, relaxed(2));\n\njulia> ΔNout(v1 => relaxed(2), v2 => -1);\n\n\n\n\n\n","category":"method"},{"location":"reference/advanced/size/#NaiveNASlib.ΔNout","page":"Size Strategies","title":"NaiveNASlib.ΔNout","text":"ΔNout <: AbstractJuMPΔSizeStrategy\nΔNout{T, V, F}(Δs::Dict{V, Int}, fallback::F)\n\nStrategy for changing nout of vertices.\n\nFor each key-value pair in v, Δ in Δs, change nout(v) by Δ, i.e new size is nout(v) + Δ.\n\nIf T == Exact, size change will be added as a constraint to the model which means that the operation will fail if it is not possible to change nout(v) by exactly Δ.\n\nIf T == Relaxed, size change will be added as an objective to the model which means that nout(v) might  not change by exactly Δ. In addition, a constraint that nout(v) must change is also added.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.WithUtilityFun","page":"Size Strategies","title":"NaiveNASlib.WithUtilityFun","text":"WithUtilityFun{F, S} <: AbstractΔSizeStrategy\nWithUtilityFun(utilityfun::F, strategy::S)\n\nApplies neuron indices selection with strategy and using utilityfun to compute the utility of neurons indices.\n\nNote that utilityfun will override any utility function supplied in function call. Thus it is possible use  WithUtilityFun to change utility function e.g. when switching to a fallback strategy.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.UpperInsertBound","page":"Size Strategies","title":"NaiveNASlib.UpperInsertBound","text":"UpperInsertBound{V<:AbstractDict{<:AbstractVertex, <:Integer}, S, F} <: DecoratingJuMPΔSizeStrategy\nUpperInsertBound(vbounds; strategy, fallback)\nUpperInsertBound(vs, bound::Integer; strategy, fallback)\n\nSets upper bound for how many new neurons to insert of each vertex v in vbounds to vbounds[v] and then applies neuron indices  selection with strategy (default DefaultJuMPΔSizeStrategy).\n\nAlternatively, sets the upper bound of each vertex in vs to bound. Applies bound to all vertices if vs is empty.\n\nMostly useful to minimize solver time in cases when one does not want any new neurons as disallowing this allows skipping a couple of constraints.\n\nIf it fails, the operation will be retried with the fallback strategy (default ΔSizeFailNoOp).\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.WithKwargs","page":"Size Strategies","title":"NaiveNASlib.WithKwargs","text":"WithKWargs{KW, S} <: AbstractAfterΔSizeStrategy\nWithKwargs(strategy; kwargs...)\n\nAdds keyword argument kwargs to any calls to Δsize! after sizes have been determined.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.LogΔSizeExec","page":"Size Strategies","title":"NaiveNASlib.LogΔSizeExec","text":"LogΔSizeExec <: AbstractJuMPΔSizeStrategy\nLogΔSizeExec(msgfun)\nLogΔSizeExec(msgfun, level::Logging.LogLevel)\nLogΔSizeExec(msgfun, level::Logging.LogLevel, andthen::AbstractJuMPΔSizeStrategy)\n\nLogs msgfun(v) at log level level, then executes AbstractJuMPΔSizeStrategy andthen for vertex v.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.ThrowΔSizeFailError","page":"Size Strategies","title":"NaiveNASlib.ThrowΔSizeFailError","text":"ThrowΔSizeFailError <: AbstractJuMPΔSizeStrategy\nThrowΔSizeFailError(msg::String)\n\nThrows an ΔSizeFailError with message msg.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.ΔSizeFailNoOp","page":"Size Strategies","title":"NaiveNASlib.ΔSizeFailNoOp","text":"ΔSizeFailNoOp <: AbstractJuMPΔSizeStrategy\nΔSizeFailNoOp()\n\nDoes not perform any action.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.AlignNinToNout","page":"Size Strategies","title":"NaiveNASlib.AlignNinToNout","text":"AlignNinToNout{S, F} <: DecoratingJuMPΔSizeStrategy\nAlignNinToNout(;vstrat::S, fallback::F)\nAlignNinToNout(vstrat::S, fallback::F)\n\nAdds variables and constraints for nin(vi) == nout.(inputs(vi)).\n\nGenerally useful when doing structural changes such are removing/adding vertices or edges.\n\nIf it fails, the operation will be retried with the fallback strategy (default ΔSizeFailNoOp).\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.TruncateInIndsToValid","page":"Size Strategies","title":"NaiveNASlib.TruncateInIndsToValid","text":"TruncateInIndsToValid{S} <: AbstractΔSizeStrategy\nTruncateInIndsToValid()\nTruncateInIndsToValid(s::S)\n\nEnsures that all selected input indices are within range of existing input indices after applying s  (default DefaultJuMPΔSizeStrategy).\n\nNot needed in normal cases, but certain structural mutations (e.g create_edge!) may cause this to happen  due to how constraints are (not) created when original sizes do not align in conjunction with how result of  selection is interpreted.\n\nAn example of when it is needed is when adding an edge from vertex vi to an invariant vertex vo where  nout(vi) > nout(vo). In this case it is expected that the result of the optimization is that the indices 1:nout(vi) of vi shall be kept. However, this will propagate to vo which will be  instructed to keep indices it does not have. With this strategy, all indices which are larger than nout(vo) will be replaced by -1 (which indicates that new parameters shall be created) \n\nWhile this may be considered a flaw in the output selection procedure, it is rare enough so that in most cases  when it happens it is the result of a user error or lower level bug. Therefore this strategy is left optional  to be used only in cases when mismatches are expected.\n\nNote that in most normal cases, this has no effect since vertices capable of getting new input edges generally  don't have parameters.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.TimeLimitΔSizeStrategy","page":"Size Strategies","title":"NaiveNASlib.TimeLimitΔSizeStrategy","text":"TimeLimitΔSizeStrategy{S} <: DecoratingJuMPΔSizeStrategy\nTimeLimitΔSizeStrategy(limit::Number)\nTimeLimitΔSizeStrategy(limit::Number, base::S)\n\nSets the time limit for the solver to limit. Use strategy base for all other aspects. \n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.TimeOutAction","page":"Size Strategies","title":"NaiveNASlib.TimeOutAction","text":"TimeOutAction{S,A,F} <: DecoratingJuMPΔSizeStrategy\nTimeOutAction(action::A, base::S, fallback::F)\nTimeOutAction(base; fallback)\n\nCalls action(model) if JuMP model model has status MOI.TIME_LIMIT after optimization stops. Use strategy base for all other aspects.\n\nDefault action is to display a warning and then apply fallback (default ΔSizeFailNoOp).\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.AfterΔSizeCallback","page":"Size Strategies","title":"NaiveNASlib.AfterΔSizeCallback","text":"AfterΔSizeCallback{F, S} <: AbstractAfterΔSizeStrategy\nAfterΔSizeCallback(cbfun::F, basestrat::S=ThrowΔSizeFailError())\n\nCalls cbfun(v, Δ, isnout) for all vertices which change size after having been asked to change their sizes as a result of basestrat.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/size/#NaiveNASlib.logafterΔsize","page":"Size Strategies","title":"NaiveNASlib.logafterΔsize","text":"logafterΔsize(printfun=nameorrepr;level=Logging.Info, base=DefaultJuMPΔSizeStrategy())\n\nReturn an AfterΔSizeCallback configured to log size changes with log level level.\n\nFor a given vertex v, printfun(v) will be used in the logged string.\n\nStrategy base will be used to change sizes (e.g if Δsize!(logafterΔsize(base)) is called).\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/size/#NaiveNASlib.validateafterΔsize","page":"Size Strategies","title":"NaiveNASlib.validateafterΔsize","text":"validateafterΔsize(printfun=nameorrepr; base=DefaultJuMPΔSizeStrategy())\n\nReturn an AfterΔSizeCallback configured to validate that sizes (nin and nout) are consistent after a size change and throw a ΔSizeFailError if validation fails.\n\nFor a given vertex v, printfun(v) will be used in the error message should the size validation fail.\n\nStrategy base will be used to change sizes (e.g if Δsize!(validateafterΔsize(base)) is called).\n\n\n\n\n\n","category":"function"},{"location":"reference/extend/misc/#Other-Functions","page":"Other Functions","title":"Other Functions","text":"","category":"section"},{"location":"reference/extend/misc/","page":"Other Functions","title":"Other Functions","text":"Imported to namespace by","category":"page"},{"location":"reference/extend/misc/","page":"Other Functions","title":"Other Functions","text":"using NaiveNASlib.Extend","category":"page"},{"location":"reference/extend/misc/#NaiveNASlib.Δsize!-Tuple{Any, AbstractVector, AbstractVector}","page":"Other Functions","title":"NaiveNASlib.Δsize!","text":"Δsize!(f::F, ins::AbstractVector, outs::AbstractVector; kwargs...)\n\nApply the changes to f so that input neurons in ins and output neurons in outs are selected and/or inserted.\n\nArgument outs is a vector of indices to select/insert while ins has one vector of indices per input vertex.\n\nShall be implemented for any type F which holds parameters for which the shape shall be modified by NaiveNASlib.\n\nTip: the function parselect can be used to change parameter arrays according to ins and outs.\n\nTip: kwargs can be passed using WithKwargs.\n\n\n\n\n\n","category":"method"},{"location":"reference/extend/misc/#NaiveNASlib.parselect","page":"Other Functions","title":"NaiveNASlib.parselect","text":"parselect(pars::AbstractArray{T,N}, elements_per_dim...; newfun = (T, dim, size...) -> 0) where {T, N}\n\nReturn a new array of same type as pars which has a subset of the elements of pars as well as potentially new elements.\n\nWhich elements to select/insert is determined by elements_per_dim which is a Pair{Int, Vector{Int}} mapping  dimension (first memeber) to which elements to select/insert in that dimension (second memeber).\n\nFor a each dim=>elems pair, the following holds: selectdim(output, dim, i) == selectdim(pars, dim, elems[i])  if elems[i] is positive and selectdim(output, dim, i) .== newfun(T, dim, size)[j] if elems[i] is the j:th negative value and size is sum(elems .< 0).\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend\n\njulia> pars = reshape(1:3*5, 3,5)\n3×5 reshape(::UnitRange{Int64}, 3, 5) with eltype Int64:\n 1  4  7  10  13\n 2  5  8  11  14\n 3  6  9  12  15\n \njulia> NaiveNASlib.parselect(pars, 1 => [-1, 1,3,-1,2], 2=>[3, -1, 2, 1]; newfun = (T, d, s...) -> fill(-T(d), s))\n5×4 Matrix{Int64}:\n -1  -2  -1  -1\n  7  -2   4   1\n  9  -2   6   3\n -1  -2  -1  -1\n  8  -2   5   2\n\n\n\n\n\n","category":"function"},{"location":"reference/extend/misc/#NaiveNASlib.vertex","page":"Other Functions","title":"NaiveNASlib.vertex","text":"vertex(trait::MutationTrait, computation, inputs::AbstractVertex...; traitdecoration=identity)\nvertex(trait::MutationTrait, vname::AbstractString, computation, inputs::AbstractVertex...; traitdecoration=identity)\nvertex(trait::MutationTrait, computation, vname::AbstractString, inputs::AbstractVertex...; traitdecoration=identity)\n\nReturn a mutable computation type vertex.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = NaiveNASlib.vertex(NaiveNASlib.SizeInvariant(), x -> 5x, inputvertex(\"input\", 1));\n\njulia> v(3)\n15\n\n\n\n\n\n","category":"function"},{"location":"reference/extend/misc/#NaiveNASlib.compconstraint!","page":"Other Functions","title":"NaiveNASlib.compconstraint!","text":"compconstraint!(case, s, v, data)\n\nAdd constraints on the computation (e.g. neural network layer) for AbstractVertex v using strategy s.\n\nExtra info like the model and variables is provided in data.\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/mutatevertex/#Vertex-Mutation","page":"Vertex Mutation","title":"Vertex Mutation","text":"","category":"section"},{"location":"reference/simple/mutatevertex/","page":"Vertex Mutation","title":"Vertex Mutation","text":"While most mutating functions operate on a single vertex or few for convenience, they typically make other modifications in the graph for it to stay size consistent. This is possible due to how vertices are able to provide their neighbours.","category":"page"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.Δnin!","page":"Vertex Mutation","title":"NaiveNASlib.Δnin!","text":"Δnin!([utilityfun], v, Δ...)\nΔnin!([utilityfun], v1 => Δ1, v2 => Δ2,...)\nΔnin!([utilityfun], Δs::AbstractDict)\n\nChange input size of all provided vertices with the associated Δ and make the appropriate changes to other vertices so that the graph is aligned w.r.t activations. Return true if successful (false if not successful).\n\nFor Δs provided as integers it must be possible to change the size by exactly Δ or else the attempt will be considered failed. A failed attempt will be retried immediately in relaxed form where the wanted size changes are moved to the objective. The relaxation means that input size might not change by exactly Δ. Use relaxed(Δ) to indicate that a size change is  relaxed in the initial attempt. \n\nFor vertices with more than one input, the size change must be expressed as a tuple with one element per input.  Use missing to indicate that no special treatment is needed for an input. Both missing and relaxed can be mixed freely inside and outside the tuples (see examples).\n\nNote that the above constrain makes Δnin! much more cumbersome to use compared to Δnout! and in most cases there are no direct advantages of using Δnin! over Δnout! as they both boil down to the same thing. \n\nArgument utilityfun provides a vector utility = utilityfun(vx) for any vertex vx in the same graph as v where  utility[i] > utility[j] indicates that output neuron index i shall be preferred over j for vertex vx. It may also provide a scalar which will be used as utility of all neurons of vx. If not provided, defaultutility(vx) will be used.\n\nNote that Δnin!([utilityfun], args...) is equivalent to  Δsize!([utilityfun], ΔNin(args...)).\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend, NaiveNASlib.Advanced\n\njulia> module TestNNLib\n           using NaiveNASlib, NaiveNASlib.Extend\n           mutable struct Affine{T} W::Matrix{T} end\n           NaiveNASlib.nout(a::Affine) = size(a.W, 1)\n           NaiveNASlib.nin(a::Affine) = [size(a.W, 2)]\n           NaiveNASlib.Δsize!(a::Affine, ins::AbstractVector, outs::AbstractVector) = a.W = parselect(a.W, 2=>ins[1], 1=>outs)\n           affine(in, outsize) = absorbvertex(Affine(ones(outsize, nout(in))), in)\n           export affine\n       end;\n\njulia> using .TestNNLib;\n\njulia> iv = affine(inputvertex(\"in\", 3), 6);\n\njulia> v1 = affine(iv, 4);\n\njulia> v2 = affine(iv, 5);\n\njulia> Δnin!(v1, 3);\n\njulia> Δnin!(v1 => -3, v2 => -2);\n\njulia> Δnin!(Dict(v1 => 3, v2 => 2));\n\njulia> v3 = conc(affine(iv, 4), affine(iv, 5), affine(iv, 6); dims=2);\n\njulia> v4 = conc(affine(iv, 7), affine(iv, 8); dims=2);\n\njulia> Δnin!(v3, 3, missing, 2);\n\njulia> Δnin!(v3 => (3, missing, 2), v4 => (-2, 0));\n\njulia> Δnin!(v3, relaxed(3), missing, 2);\n\njulia> Δnin!(v3 => (relaxed(3), missing, 2), v4 => relaxed(-2, 0)) do v\n           randn(nout(v))\n       end;\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.Δnout!","page":"Vertex Mutation","title":"NaiveNASlib.Δnout!","text":"Δnout!([utilityfun], v, Δ...)\nΔnout!([utilityfun], v1 => Δ1, v2 => Δ2,...)\nΔnout!([utilityfun], Δs::AbstractDict)\n\nChange output size of all provided vertices with the associated Δ and make the appropriate changes to other vertices so that the graph is aligned w.r.t activations. Return true if successful (false if not successful).\n\nFor Δs provided as integers it must be possible to change the size by exactly Δ or else the attempt will be considered failed. A failed attempt will be retried immediately in relaxed form where the wanted size changes are moved to the objective. The relaxation means that output size might not change by exactly Δ. Use relaxed(Δ) to indicate that a size change is  relaxed in the initial attempt. \n\nArgument utilityfun provides a vector utility = utilityfun(vx) for any vertex vx in the same graph as v where  utility[i] > utility[j] indicates that output neuron index i shall be preferred over j for vertex vx. It may also provide a scalar which will be used as utility of all neurons of vx. If not provided, defaultutility(vx) will be used.\n\nNote that Δnout!([utilityfun], args...) is equivalent to Δsize!([utilityfun], ΔNout(args...)).\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend, NaiveNASlib.Advanced\n\njulia> module TestNNLib\n           using NaiveNASlib, NaiveNASlib.Extend\n           mutable struct Affine{T} W::Matrix{T} end\n           NaiveNASlib.nout(a::Affine) = size(a.W, 1)\n           NaiveNASlib.nin(a::Affine) = [size(a.W, 2)]\n           NaiveNASlib.Δsize!(a::Affine, ins::AbstractVector, outs::AbstractVector) = a.W = parselect(a.W, 2=>ins[1], 1=>outs)\n           affine(in, outsize) = absorbvertex(Affine(ones(outsize, nout(in))), in)\n           export affine\n       end;\n\njulia> using .TestNNLib;\n\njulia> iv = affine(inputvertex(\"in\", 3), 6);\n\njulia> v1 = affine(iv, 4);\n\njulia> v2 = affine(iv, 5);\n\njulia> Δnout!(v1, 3);\n\njulia> Δnout!(v1 => -3, v2 => -2);\n\njulia> Δnout!(Dict(v1 => 3, v2 => 2));\n\njulia> Δnout!(v1, relaxed(2));\n\njulia> Δnout!(v1 => relaxed(2), v2 => -1) do v\n           randn(nout(v))\n       end;\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.Δsize!-Tuple{AbstractΔSizeStrategy}","page":"Vertex Mutation","title":"NaiveNASlib.Δsize!","text":"Δsize!(s::AbstractΔSizeStrategy) \nΔsize!(utilityfun, s::AbstractΔSizeStrategy)\n\nChange size of (potentially) all vertices which s has a chance to impact the size of.\n\nArgument utilityfun provides a vector utility = utilityfun(vx) for any vertex vx in the same graph as v where  utility[i] > utility[j] indicates that output neuron index i shall be preferred over j for vertex vx. It may  also provide a scalar which will be used as utility of all neurons of vx. If not provided, defaultutility(vx) will be used.\n\n\n\n\n\n","category":"method"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.Δsize!-Tuple{CompGraph}","page":"Vertex Mutation","title":"NaiveNASlib.Δsize!","text":"Δsize!([utilityfun], [s::AbstractΔSizeStrategy], g::CompGraph)\nΔsize!([utilityfun], [s::AbstractΔSizeStrategy], v::AbstractVertex)\n\nChange size of (potentially) all vertices of graph g (or graph to which v is connected) according to the provided  AbstractΔSizeStrategy (default UpperInsertBound).\n\nReturn true of operation was successful, false otherwise.\n\nArgument utilityfun provides a vector utility = utilityfun(vx) for any vertex vx in the same graph as v where  utility[i] > utility[j] indicates that output neuron index i shall be preferred over j for vertex vx. It may  also provide a scalar which will be used as utility of all neurons of vx. If not provided, defaultutility(vx) will be used.\n\n\n\n\n\n","category":"method"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.Δsize!-Tuple{AbstractVector{<:AbstractVertex}}","page":"Vertex Mutation","title":"NaiveNASlib.Δsize!","text":"Δsize!([utilityfun], [s::AbstractΔSizeStrategy], vs::AbstractVector{<:AbstractVertex})\n\nChange size of (potentially) all vertices in vs according to the provided AbstractΔSizeStrategy (default  UpperInsertBound).\n\nArgument utilityfun provides a vector utility = utilityfun(vx) for any vertex vx in the same graph as v where  utility[i] > utility[j] indicates that output neuron index i shall be preferred over j for vertex vx. It may also provide a scalar which will be used as utility of all neurons of vx. If not provided, defaultutility(vx)  will be used.\n\n\n\n\n\n","category":"method"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.relaxed","page":"Vertex Mutation","title":"NaiveNASlib.relaxed","text":"relaxed(Δ)\n\nReturn Δ => Relaxed() which indicates that Δ shall be relaxed when changing size.\n\nSee Δnout! and Δnin!.\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/mutatevertex/#Base.insert!","page":"Vertex Mutation","title":"Base.insert!","text":"insert!(vin::AbstractVertex, factory::Function, outselect::Function=identity)\n\nReplace vin as input to all outputs of vin with vertex produced by factory.\n\nThe function factory takes vin as input.\n\nExample:\n\nBefore:\n\n    vin\n   / | \\\n  /  |  \\\n v₁ ... vₙ\n\nAfter:\n\n    vin\n     |\n   vnew₁\n     ⋮\n   vnewₖ\n   / | \\\n  /  |  \\\n v₁ ... vₙ\n\nNote that the connection vin -> vnew₁ as well as all connections vnewₚ -> vnewₚ₊₁ is done by factory in the above example.\n\nThe function outselect can be used to select a subset of outputs to replace (default all).\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.remove!","page":"Vertex Mutation","title":"NaiveNASlib.remove!","text":"remove!(v::MutationVertex, strategy=RemoveStrategy())\n\nRemoves v from the graph by removing it from its inputs and outputs.\n\nIt is possible to supply a strategy for how to 1) reconnect the inputs and outputs of v and 2) align the input and output sizes of the inputs and outputs of v.\n\nDefault strategy is to first set nin==nout for v and then connect all its  inputs to all its outputs.\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.create_edge!","page":"Vertex Mutation","title":"NaiveNASlib.create_edge!","text":"create_edge!(from::AbstractVertex, to::AbstractVertex; [pos], [strategy])\n\nCreate and edge from from to to at index pos in inputs(to).\n\nSizes will be adjusted based on given strategy.\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/mutatevertex/#NaiveNASlib.remove_edge!","page":"Vertex Mutation","title":"NaiveNASlib.remove_edge!","text":"remove_edge!(from::AbstractVertex, to::AbstractVertex; [nr], [strategy])\n\nRemove edge from from to to.\n\nIf there are multiple edges from from to to then nr can be used to distinguish which one shall be removed.\n\nSizes will be adjusted based on given strategy.\n\n\n\n\n\n","category":"function"},{"location":"terminology/#Terminology","page":"Terminology","title":"Terminology","text":"","category":"section"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"NaiveNASlib tries to use standard graph and neural network terminology to whatever extent possible. Here is a short summary of the  important concepts and what they mean to NaiveNASlib. This section is best read after the Quick Tutorial to make  it somewhat more concrete.","category":"page"},{"location":"terminology/#Graph","page":"Terminology","title":"Graph","text":"","category":"section"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Since the only types of graphs NaiveNASlib cares about are directed acyclic graphs which describe the data flow through a  function, the term 'graph' is often used interchangeably with terms like 'model', 'function' and 'neural network'.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Furthermore, due to how vertices in NaiveNASlib also contain their edges, a single vertex from a graph recursively describes the whole graph.","category":"page"},{"location":"terminology/#Vertex","page":"Terminology","title":"Vertex","text":"","category":"section"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Vertices are the fundamental unit which NaiveNASlib works with when changing the structure of a graph. A vertex can be queried for both input and output vertices as well as its current input and output size (see Neuron below). ","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Most vertices in the graph wrap a function which from the point of view of NaiveNASlib are the primitives of the computation  graph. NaiveNASlib does not have a firm opinion on what functions are considered primitive though. One vertex in the graph can wrap a single layer (or something even simpler) while another can wrap a whole computation graph.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"As seen in the Quick Tutorial, how to adjust the input/output sizes of the vertices in the graph depends on the  computation.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"NaiveNASlib uses traits to classify three basic types of vertices so that it does not have to implement rules for every possible primitive. The core idea of NaiveNASlib is basically to annotate the type of vertex in the graph so that it knows  what is the proper way to deal with the neighboring vertices when mutating a vertex.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"This is done through labeling vertices into three major types:","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"SizeAbsorb: Assumes nout(v) and nin(v) may change independently. This means that size changes   are absorbed by this vertex in the sense they don't propagate further. Most typical neural network layers with parameter   arrays fall into this category.\nSizeStack: Assumes nout(v) == sum(nin(v)). This means that size changes propagate forwards (i.e. input -> output and   output -> input). The main operation in this category is concatenation of activations. \nSizeInvariant: Assumes [nout(v)] == unique(nin(v)). This means that size changes propagate both forwards and backwards   as changing any input size or the output size means all others must change as well. In this category we typically find element wise operations, but also normalization and pooling operations tend to fall into this category. ","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"NaiveNASlib also uses the term SizeTransparent to denote the latter two (i.e any vertex which is not SizeAbsorb). To use this library to mutate architectures for some neural network library basically means annotating up the above type for  each layer type and connect parameter dimensions to input and output sizes.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Note one typically does not need to interact with the traits when just using NaiveNASlib and they are not exported by default. The functions for Vertex Creation attaches the proper trait to the vertex when creating it.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"While the above covers a substantial set of operations, it is possible to implement special rules for individual computations as well.","category":"page"},{"location":"terminology/#Edge","page":"Terminology","title":"Edge","text":"","category":"section"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Contrary to more general graph frameworks, edges in NaiveNASlib are implicit in the sense that each vertex stores its input  and output vertices. Edges are primarily used when evaluating the graph as a function as well as when formulating the  constraints for keeping the graph size aligned.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"While this is typically seen as impractical in more general graph analyzing frameworks, the scope of NaiveNASlib makes this a relatively sane choice as it allows for the convenience of passing a single vertex to mutating functions without having to haul around the whole graph object.","category":"page"},{"location":"terminology/#Neuron","page":"Terminology","title":"Neuron","text":"","category":"section"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Neuron is the name NaiveNASlib uses for the indices of the relevant dimension of the arrays passed between vertices. For example, if one vertex v takes a vector of size N as input and returns a vector of size M it has N input neurons and M output neurons. This is synonymous with saying that v has input size N and output size M and nin(v) == N and nout(v) == M.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"When changing input or output size v will be given indices of the neurons to keep as well as where to insert new neurons. NaiveNASlib has then made sure that other vertices have gotten indices so that all remaining  neurons stay connected to the same neurons they were connected to previously. See Closer look at how weights are modified for a concrete example.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"NaiveNASlib does not have the ability to figure out what input and output sizes a function wrapped in a vertex have by itself, so this must be provided by the implementation. See nout and nin.","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Examples of how to determine the input and output size for common layer types:","category":"page"},{"location":"terminology/","page":"Terminology","title":"Terminology","text":"Fully connected layers: The size of the non-batch dimension, typically the rows/columns of the weight matrix.\nRecurrent layers: The size of the dimension which is neither batch nor time. \nConvolutional layers: The number of input/output channels. ","category":"page"},{"location":"examples/quicktutorial/#Quick-Tutorial","page":"Quick Tutorial","title":"Quick Tutorial","text":"","category":"section"},{"location":"examples/quicktutorial/#Construct-a-very-simple-graph","page":"Quick Tutorial","title":"Construct a very simple graph","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Just to get started, lets create a simple graph for the summation of two numbers.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"using NaiveNASlib, Test # We'll make use of @test below to condense verbose output","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"NaiveNASlib uses a special immutable type of vertex to annotate inputs so that one can be certain that size mutations won't suddenly change the input shape of the model.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"in1 = inputvertex(\"in1\", 1);\nin2 = inputvertex(\"in2\", 1);\nnothing #hide","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"In this example we could have done without them as we won't have any parameters to change the size of, but lets show things as they are expected to be used.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Create a new vertex which computes the sum of in1 and in2:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"add = \"add\" >> in1 + in2;\nnothing #hide","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"NaiveNASlib lets you do this using + which creates a new vertex which sums it inputs. Use >> to attach a name to the vertex when using infix operations. Naming vertices is completely optional, but it is quite helpful as can be seen below.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"CompGraph helps evaluating the whole graph as a function.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"graph = CompGraph([in1, in2], add)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"The show function for CompGraph just redirects to graphsummary until I can find a better way to print it.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Evaluate the function represented by graph by just calling it.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"graph(2,3)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"graph(100,200)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"The vertices function returns the vertices in topological order.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test vertices(graph) == [in1, in2, add]\n@test name.(vertices(graph)) == [\"in1\", \"in2\", \"add\"]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"The graphsummary function can be used to print a summary table:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"graphsummary(graph, name, \"Name of inputs\" => v -> name.(inputs(v)))","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"CompGraphs can be indexed:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test graph[begin] == graph[1] == in1\n@test graph[end] == graph[3] == add\n@test graph[begin:end] == vertices(graph)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"This is a bit slow though as it traverses the whole graph each time. It is better to call vertices first and then apply the indexing if one needs to do this many times.","category":"page"},{"location":"examples/quicktutorial/#Modify-a-graph","page":"Quick Tutorial","title":"Modify a graph","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Now lets look at how to make use of it to modify the structure of a neural network. Since batteries are excluded, lets first create a tiny neural network library and do the wiring so that NaiveNASlib can work with it.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"module TinyNNlib\n    using NaiveNASlib\n    # A simple linear layer\n    mutable struct LinearLayer{T}\n        W::Matrix{T}\n    end\n    # Normally ones uses something like randn here, but this makes output\n    # in examples easier on the eyes\n    LinearLayer(nin, nout) = LinearLayer(ones(Int, nout, nin))\n    (l::LinearLayer)(x) = l.W * x\n\n    # NaiveNASlib needs to know what LinearLayer considers its output and input size\n    # In this case it is the number of rows and columns of the weight matrix\n    # Input size is always a vector since vertices might have multiple inputs\n    NaiveNASlib.nin(l::LinearLayer) = [size(l.W, 2)]\n    NaiveNASlib.nout(l::LinearLayer) = size(l.W, 1)\n\n    # We also need to tell NaiveNASlib how to change the size of LinearLayer\n    # The Δsize! function will receive indices to keep from existing weights\n    # as well as where to insert new rows/columns\n    function NaiveNASlib.Δsize!(l::LinearLayer, newins::AbstractVector, newouts::AbstractVector)\n        # newins is a vector of vectors as vertices may have more than one input\n        # LinearLayer has only one howevever\n        # The function NaiveNASlib.parselect can be used to interpret newins and newouts.\n        # We just need to tell it along which dimensions to apply them.\n        l.W = NaiveNASlib.parselect(l.W, 1=>newouts, 2=>only(newins))\n    end\n\n    # This makes LinearLayer print nice in the graphsummary table\n    Base.show(io::IO, l::LinearLayer) = print(io, \"LinearLayer(\", only(nin(l)), \" => \" ,nout(l), ')')\n\n    # Helper function which creates a LinearLayer wrapped in an vertex in a computation graph.\n    # This creates a Keras-like API\n    linearvertex(in, outsize) = absorbvertex(LinearLayer(nout(in), outsize), in)\n    export linearvertex, LinearLayer\nend;\nnothing #hide","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"There are a handful of other functions one can implement to e.g. provide better defaults and offer other forms of convenience, but here we use the bare minimum to get ourselves started. Some examples of this is provided further down.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"In practice one might not want to create a whole neural network library from scratch, but rather incorporate NaiveNASlib with an existing library in a glue package. It might appear that this will inevitably lead to type-piracy as neither the layer definitions nor the functions (e.g. nout, nin) would belong to the glue package. However, one typically wants to wrap the layers in some intermediate type anyways. For instance, NaiveNASflux needs to wrap the layers from Flux in a mutable container as the layers themselves are not mutable.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Lets do a super simple example where we make use of the tiny neural network library to create a model and then modify it:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"using .TinyNNlib\ninvertex = inputvertex(\"input\", 3);\nlayer1 = linearvertex(invertex, 4);\nlayer2 = linearvertex(layer1, 5);\nnothing #hide","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Vertices may be called to execute their computation alone. We generally outsource this work to CompGraph, but now we are trying to illustrate how things work.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"batchsize = 2\nbatch = randn(nout(invertex), batchsize)\ny1 = layer1(batch)\n@test size(y1) == (nout(layer1), batchsize) == (4, 2)\n\ny2 = layer2(y1)\n@test size(y2) == (nout(layer2), batchsize) == (5, 2)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Lets change the output size of layer1. First check the input sizes so we have something to compare to.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test [nout(layer1)] == nin(layer2) == [4]\n@test Δnout!(layer1 => -2) # Returns true if successful\n@test [nout(layer1)] == nin(layer2) == [2]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"And now the weight matrices have changed!","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"The graph is still operational of course but the sizes of the activations have changed.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"y1 = layer1(batch)\n@test size(y1) == (nout(layer1), batchsize) == (2, 2)\n\ny2 = layer2(y1)\n@test size(y2) == (nout(layer2), batchsize) == (5, 2)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"As can be seen above, the consequence of changing the output size of layer1 was that the input size of layer2 also was changed. This is of course required for the computation graph to not throw a dimension mismatch error when being executed.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Besides the very simple graph, this mutation was trivial because the sizes of the input and output dimensions of LinearLayer's parameters can change independently as they are the rows and columns of the weight matrix. This is expressed by giving the layers the mutation size trait SizeAbsorb in the lingo of NaiveNASlib, meaning that a change in number of input/output neurons does not propagate further in the graph.","category":"page"},{"location":"examples/quicktutorial/#A-more-elaborate-example","page":"Quick Tutorial","title":"A more elaborate example","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"While the previous example was simple enough to be done by hand, things can quickly get out of hand when using:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Layers which require nin==nout, e.g. batch normalization and pooling.\nElement wise operations such as activation functions or just element wise arithmetics (e.g + used in residual connections).\nConcatenation of activations.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Lets use a small but non-trivial model including all of the above. We begin by making a helper which creates a vertex which does elementwise scaling of its input:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"scalarmult(v, s::Number) = invariantvertex(x -> x .* s, v);\nnothing #hide","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"When multiplying with a scalar, the output size is the same as the input size. This vertex type is said to be size invariant (in lack of better words), hence the name invariantvertex.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Ok, lets create the model:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"# First a few `LinearLayer`s\ninvertex = inputvertex(\"input\", 6);\nstart = linearvertex(invertex, 6);\nsplit = linearvertex(start, nout(invertex) ÷ 3);\n\n# Concatenation means the output size is the sum of the input sizes\njoined = conc(scalarmult(split,2), scalarmult(split,3), scalarmult(split,5), dims=1);\n\n# Elementwise addition is of course also size invariant\nout = start + joined;\n\n# CompGraph to help us run the whole thing. Don't forget to use [`graphsummary`](@ref)\n# to help understand the structure\ngraph = CompGraph(invertex, out)\ngraphsummary(graph, nin, nout)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"As seen above, the anonymous function in scalarmult does not print nicely. Consider using a callable struct and implement Base.show for it.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test graph((ones(6))) == [78, 78, 114, 114, 186, 186]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Now we have a somewhat complex set of size relations at our hand since the sizes are constrained so that","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"start and joined must have the same output size due to element wise addition.\njoined will always have 3 times the output size of split since there are no size absorbing vertices between them.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Modifying this graph manually would of course be manageable (albeit a bit cumbersome) if we created the model by hand and knew it inside out. When things like the above emerges out of a neural architecture search things are less fun though and this is where use of NaiveNASlib will really pay off.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Ok, lets try to increase the size of the vertex out by 2. Before we do that, lets have a look at the sizes of the vertices in the graph to have something to compare to.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test [nout(start)] == nin(split) == [3nout(split)] == [sum(nin(joined))] == [nout(out)] == [6]\n@test [nout(start), nout(joined)] == nin(out) == [6, 6]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"In many cases it is useful to hold on to the old graph before mutating","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"parentgraph = deepcopy(graph);\nnothing #hide","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"It is not possible to change the size of out by exactly 2 due to 1. and 2. above. By default, NaiveNASlib warns when this happens and then tries to make the closest possible change. If we don't want the warning, we can tell NaiveNASlib to relax and make the closest possible change right away:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test Δnout!(out => relaxed(2))\n\n@test [nout(start)] == nin(split) == [3nout(split)] == [sum(nin(joined))] == [nout(out)] == [9]\n@test [nout(start), nout(joined)] == nin(out) == [9, 9]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"As we can see above, the size change rippled through the graph due to the size relations described above. Pretty much every vertex was affected.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Lets evaluate the graph just to verify that we don't get a dimension mismatch error.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test graph((ones(6))) == [78, 78, 0, 114, 114, 0, 186, 186, 0]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"TinyNNlib uses parselect which defaults to inserting rows/columns of zeros when size increases. This helps the graph maintain the same function after mutation. In this case we changed the size of the output layer so we don't have the exact same function though, but hopefully it is clear why e.g. a linear layer after out would have made it produce the same output.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Copy is still intact of course.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test parentgraph((ones(6))) == [78, 78, 114, 114, 186, 186]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"While we still have the complex model in scope, lets show a few more way to change the sizes. See the built in documentation for more information.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"It is possible to supply a utility function for telling the utility of each neuron in a vertex. NaiveNASlib will prioritize keeping the neurons with higher utility.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Prefer high indices:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"graphhigh = deepcopy(graph)\n@test Δnout!(v -> 1:nout(v), graphhigh[end] => -3)\n@test graphhigh((ones(6))) == [42, 0, 60, 0, 96, 0]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Perfer low indices:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"graphlow = deepcopy(graph)\n@test Δnout!(v -> nout(v):-1:1, graphlow[end] => -3)\n@test graphlow((ones(6))) == [78, 78, 114, 114, 186, 186]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"A simple approach when doing structured pruning is to prefer neurons with high magnitude. Here is how to set that as the default for LinearLayer. This is something one should probably implement in TinyNNlib instead.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"using Statistics: mean\nNaiveNASlib.defaultutility(l::LinearLayer) = mean(abs, l.W, dims=2)\n\ngraphhighmag = deepcopy(graph)\n@test Δnout!(graphhighmag[end] => -3)\n@test graphhighmag((ones(6))) == [78, 78, 114, 114, 186, 186]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"In many NAS applications one wants to apply random mutations to the graph. When doing so, one might end up in situations like this:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"badgraphdecinc = deepcopy(graph)\nv1, v2 = badgraphdecinc[[3, end]] # Imagine selecting these at random\n@test Δnout!(v1 => relaxed(-2))\n@test Δnout!(v2 => 6)\n# Now we first deleted a bunch of weights, then we added new :(\n@test badgraphdecinc((ones(6))) ==  [42, 0, 0, 60, 0, 0, 96, 0, 0]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"In such cases, it might be better to supply all wanted changes in one go and let NaiveNASlib try to come up with a decent compromise.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"goodgraphdecinc = deepcopy(graph)\nv1, v2 = goodgraphdecinc[[3, end]]\n@test Δnout!(v1 => relaxed(-2), v2 => 3) # Mix relaxed and exact size changes freely\n@test goodgraphdecinc((ones(6))) == [78, 78, 6, 0, 108, 114, 6, 6, 180, 180, 0, 0]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"It is also possible to change the input direction, but it requires specifying a size change for each input and is generally not recommended due to this.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"graphΔnin = deepcopy(graph)\nv1, v2 = graphΔnin[end-1:end]\n# Use missing to signal \"don't care\"\n@test Δnin!(v1 => (3, relaxed(2), missing), v2 => relaxed((1,2)))\n@test nin(v1) == [6, 6, 6] # Sizes are tied to nout of split so they all have to be equal\n@test nin(v2) == [18, 18] # Sizes are tied due to elementwise addition","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"A common pruning strategy is to just remove the x% of params with lowest utility. This can be done by just not putting any size requirements and assign negative utility.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"graphprune40 = deepcopy(graph)\nΔsize!(graphprune40) do v\n    utility = NaiveNASlib.defaultutility(v)\n    # We make some strong assumptions on weight distribution here for breviety :)\n    return utility .- 0.4mean(utility)\nend\n@test nout.(vertices(graphprune40)) == [6, 6, 2, 2, 2, 2, 6, 6]\n# Compare to original:\n@test nout.(vertices(graph))        == [6, 9, 3, 3, 3, 3, 9, 9]","category":"page"},{"location":"examples/quicktutorial/#Closer-look-at-how-weights-are-modified","page":"Quick Tutorial","title":"Closer look at how weights are modified","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Here we take a closer look at how the weight matrices are changed. We use the following function to create LinearLayers with easy to distinguish weights. It returns both a vertex and the LinearLayer so we can easily look at the weights:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"function vertexandlayer(in, outsize)\n    nparam = nout(in) * outsize\n    l = LinearLayer(collect(reshape(1:nparam, :, nout(in))))\n    return absorbvertex(l, in), l\nend;\nnothing #hide","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Make a simple model:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"invertices = inputvertex.([\"in1\", \"in2\"], [3,4])\nv1, l1 = vertexandlayer(invertices[1], 4)\nv2, l2 = vertexandlayer(invertices[2], 3)\nmerged = conc(v1, v2, dims=1)\nv3, l3 = vertexandlayer(invertices[1], nout(merged))\nadd = v3 + merged\nv4, l4 = vertexandlayer(merged, 2)\nCompGraph(invertices, v4)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"These weights might look a bit odd, but here we only care about making it easy to spot what has changed after size change below.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test l1.W ==\n[ 1 5  9\n  2 6 10\n  3 7 11\n  4 8 12 ]\n\n@test l2.W ==\n[ 1 4 7 10\n  2 5 8 11\n  3 6 9 12 ]\n\n@test l3.W ==\n[ 1  8 15\n  2  9 16\n  3 10 17\n  4 11 18\n  5 12 19\n  6 13 20\n  7 14 21 ]\n\n@test l4.W ==\n[ 1 3 5 7  9 11 13 ;\n  2 4 6 8 10 12 14 ]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Now, lets decrease v2 by 1 and force merged to retain its size which in turn forces v1 to grow by 1. Assign utility 10 to neurons 1 and 3 of v2 and 1 for all other neurons in the model.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test Δnout!(v2 => -1, merged => 0) do v\n    v == v2 ? [10, 1, 10] : 1\nend","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"v1 got a new row of parameters at the end:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test l1.W ==\n[ 1 5  9\n  2 6 10\n  3 7 11\n  4 8 12\n  0 0  0 ]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"v2 chose to drop its middle row as it was the output neuron with lowest utility:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test l2.W ==\n[ 1 4 7 10\n  3 6 9 12 ]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"v4 dropped the second to last column (which is aligned to the middle row of v2). and got new parameters in column 5 (which is aligned to the last row of v1):","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test l4.W ==\n[  1 3 5 7 0  9 13\n   2 4 6 8 0 10 14 ]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Oh, and since v4 is connected to v3 though add, v3 had the equivalent change to its rows:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"@test l3.W ==\n[ 1  8 15\n  2  9 16\n  3 10 17\n  4 11 18\n  0  0  0\n  5 12 19\n  7 14 21 ]","category":"page"},{"location":"examples/quicktutorial/#Other-modifications","page":"Quick Tutorial","title":"Other modifications","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Lets just do a few quick examples of the other types of modifications.","category":"page"},{"location":"examples/quicktutorial/#Add-a-vertex","page":"Quick Tutorial","title":"Add a vertex","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Using insert!:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"invertex = inputvertex(\"input\", 3)\nlayer1 = linearvertex(invertex, 5)\ngraph = CompGraph(invertex, layer1)\n\n# nvertices(g) is shortcut for length(vertices(g))\n@test nvertices(graph) == 2\n@test graph(ones(3)) == [3,3,3,3,3]\n\n# Insert a layer between invertex and layer1\n@test insert!(invertex, vertex -> linearvertex(vertex, nout(vertex))) # True if success\n\n@test nvertices(graph) == 3\n@test graph(ones(3)) == [9, 9, 9, 9, 9]","category":"page"},{"location":"examples/quicktutorial/#Remove-a-vertex","page":"Quick Tutorial","title":"Remove a vertex","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Using remove!:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"invertex = inputvertex(\"input\", 3)\nlayer1 = linearvertex(invertex, 5)\nlayer2 = linearvertex(layer1, 4)\ngraph = CompGraph(invertex, layer2)\n\n@test nvertices(graph) == 3\n@test graph(ones(3)) == [15, 15, 15, 15]\n\n# Remove layer1 and change nin of layer2 from 5 to 3\n# Would perhaps have been better to increase nout of invertex, but it is immutable\n@test remove!(layer1) # True if success\n\n@test nvertices(graph) == 2\n@test graph(ones(3)) == [3, 3, 3, 3]","category":"page"},{"location":"examples/quicktutorial/#Add-an-edge","page":"Quick Tutorial","title":"Add an edge","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Using create_edge!:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"invertices = inputvertex.([\"input1\", \"input2\"], [3, 2])\nlayer1 = linearvertex(invertices[1], 4)\nlayer2 = linearvertex(invertices[2], 4)\nadd = layer1 + layer2\nout = linearvertex(add, 5)\ngraph = CompGraph(invertices, out)\n\n@test nin(add) == [4, 4]\n# Two inputs to this graph!\n@test graph(ones(3), ones(2)) == [20, 20, 20, 20, 20]\n\n# This graph is not interesting enough for there to be a good showcase for adding a new edge.\n# Lets create a new layer which has a different output size just to see how things change\n# The only vertex which support more than one input is add\nlayer3 = linearvertex(invertices[2], 6)\n@test create_edge!(layer3, add) # True if success\n\n# NaiveNASlib will try to increase the size in case of a mismatch by default\n@test nin(add) == [6, 6, 6]\n@test graph(ones(3), ones(2)) == [28, 28, 28, 28, 28]","category":"page"},{"location":"examples/quicktutorial/#Remove-an-edge","page":"Quick Tutorial","title":"Remove an edge","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Using remove_edge!:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"invertex = inputvertex(\"input\", 4)\nlayer1 = linearvertex(invertex, 3)\nlayer2 = linearvertex(invertex, 5)\nmerged = conc(layer1, layer2, layer1, dims=1)\nout = linearvertex(merged, 3)\ngraph = CompGraph(invertex, out)\n\n@test nin(merged) == [3, 5, 3]\n@test graph(ones(4)) == [44, 44, 44]\n\n@test remove_edge!(layer1, merged) # True if success\n\n@test nin(merged) == [5, 3]\n@test graph(ones(4)) == [32, 32, 32]","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/advanced/structure/#Vertex-Connection-Strategies","page":"Vertex Connection Strategies","title":"Vertex Connection Strategies","text":"","category":"section"},{"location":"reference/advanced/structure/","page":"Vertex Connection Strategies","title":"Vertex Connection Strategies","text":"Strategies when changing connection between vertices. ","category":"page"},{"location":"reference/advanced/structure/","page":"Vertex Connection Strategies","title":"Vertex Connection Strategies","text":"Imported to namespace by","category":"page"},{"location":"reference/advanced/structure/","page":"Vertex Connection Strategies","title":"Vertex Connection Strategies","text":"using NaiveNASlib.Advanced","category":"page"},{"location":"reference/advanced/structure/#NaiveNASlib.RemoveStrategy","page":"Vertex Connection Strategies","title":"NaiveNASlib.RemoveStrategy","text":"RemoveStrategy\nRemoveStrategy()\nRemoveStrategy(rs::AbstractConnectStrategy)\nRemoveStrategy(as::AbstractAlignSizeStrategy)\nRemoveStrategy(rs::AbstractConnectStrategy, as::AbstractAlignSizeStrategy)\n\nStrategy for removal of a vertex.\n\nConsists of an AbstractConnectStrategy for how to treat inputs and outputs of the removed vertex and an AbstractAlignSizeStrategy for how to align sizes of inputs and outputs.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.IncreaseSmaller","page":"Vertex Connection Strategies","title":"NaiveNASlib.IncreaseSmaller","text":"IncreaseSmaller <: AbstractAlignSizeStrategy\nIncreaseSmaller()\nIncreaseSmaller(;mapstrat, fallback)\n\nTry to align size by increasing in the direction (in/out) which has the smaller size. Fallback to another strategy (default DecreaseBigger) if size change is not possible.\n\nmapstrat can be used to wrap the AbstractΔSizeStrategy in a DecoratingJuMPΔSizeStrategy. Main intended usecase is WithUtilityFun. Note one might want to supply the same mapstrat to any fallback strategies. \n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.DecreaseBigger","page":"Vertex Connection Strategies","title":"NaiveNASlib.DecreaseBigger","text":"DecreaseBigger <: AbstractAlignSizeStrategy\nDecreaseBigger()\nDecreaseBigger(;fallback, mapstrat)\n\nTry to align size by decreasing in the direction (in/out) which has the bigger size. Fallback to another strategy (default AlignSizeBoth) if size change is not possible.\n\nmapstrat can be used to wrap the AbstractΔSizeStrategy in a DecoratingJuMPΔSizeStrategy. Main intended usecase is WithUtilityFun. Note one might want to supply the same mapstrat to any fallback strategies. \n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.AlignSizeBoth","page":"Vertex Connection Strategies","title":"NaiveNASlib.AlignSizeBoth","text":"AlignSizeBoth <: AbstractAlignSizeStrategy\nAlignSizeBoth()\nAlignSizeBoth(;fallback, mapstrat)\n\nAlign sizes by changing both input and output. Fallback to another strategy (default FailAlignSizeWarn) if size change is not possible.\n\nmapstrat can be used to wrap the AbstractΔSizeStrategy in a DecoratingJuMPΔSizeStrategy. Main intended usecase is WithUtilityFun. Note one might want to supply the same mapstrat to any fallback strategies. \n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.PostAlign","page":"Vertex Connection Strategies","title":"NaiveNASlib.PostAlign","text":"PostAlign <: AbstractAlignSizeStrategy\nPostAlign()\nPostAlign(s::AbstractAlignSizeStrategy)\nPostAlign(s::AbstractAlignSizeStrategy, fallback)\n\nAlign sizes using a AbstractΔSizeStrategy.\n\nThis is a post-align strategy, i.e it will be applied after a structural change has been made.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.ChangeNinOfOutputs","page":"Vertex Connection Strategies","title":"NaiveNASlib.ChangeNinOfOutputs","text":"ChangeNinOfOutputs <: AbstractAlignSizeStrategy\nChangeNinOfOutputs(Δoutsize)\n\nJust sets nin of each output to the provided utility. Sometimes you just know the answer...\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.FailAlignSizeNoOp","page":"Vertex Connection Strategies","title":"NaiveNASlib.FailAlignSizeNoOp","text":"FailAlignSizeNoOp <: AbstractAlignSizeStrategy\nFailAlignSizeNoOp()\n\nDon't do any size change and return failure status.\n\nNote that this means that graphs will most likely be left corrupted state if used as a fallback.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.FailAlignSizeError","page":"Vertex Connection Strategies","title":"NaiveNASlib.FailAlignSizeError","text":"FailAlignSizeError <: AbstractAlignSizeStrategy\nFailAlignSizeError()\n\nThrows SizeAlignFailError.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.FailAlignSizeWarn","page":"Vertex Connection Strategies","title":"NaiveNASlib.FailAlignSizeWarn","text":"FailAlignSizeWarn <: AbstractAlignSizeStrategy\nFailAlignSizeWarn()\nFailAlignSizeWarn(;andthen, msgfun)\n\nLogs warning and then proceeds with the next action.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.NoSizeChange","page":"Vertex Connection Strategies","title":"NaiveNASlib.NoSizeChange","text":"NoSizeChange <: AbstractAlignSizeStrategy\nNoSizeChange()\n\nDon't do any size change.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.CheckAligned","page":"Vertex Connection Strategies","title":"NaiveNASlib.CheckAligned","text":"CheckAligned <:AbstractAlignSizeStrategy\nCheckAligned()\nCheckAligned(ifnot)\n\nCheck if sizes are already aligned before making a change and return \"go ahead\" (true) if this is the case. If not, proceed to execute another strategy (default CheckNoSizeCycle).\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.CheckNoSizeCycle","page":"Vertex Connection Strategies","title":"NaiveNASlib.CheckNoSizeCycle","text":"CheckNoSizeCycle <: AbstractAlignSizeStrategy\nCheckNoSizeCycle()\nCheckNoSizeCycle(;ifok, ifnok)\n\nCheck if a size change in one direction causes a change in the other direction and execute strategy ifnok (default FailAlignSizeWarn) if this is the case. Motivation is that removing will result in the computation graph being in an invalid state as one of the vertices must fulfill the impossible criterion  nout(v) == nout(v) + a where a > 0.\n\nIf no such cycle is detected, then proceed to execute strategy ifok (default IncreaseSmaller).\n\nWill execute strategy ifok if vertex shall not to be removed.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/structure/#NaiveNASlib.CheckCreateEdgeNoSizeCycle","page":"Vertex Connection Strategies","title":"NaiveNASlib.CheckCreateEdgeNoSizeCycle","text":"CheckCreateEdgeNoSizeCycle <: AbstractAlignSizeStrategy\nCheckCreateEdgeNoSizeCycle()\nCheckCreateEdgeNoSizeCycle(;ifok, ifnok)\n\nCheck if adding an edge creates the same type of size cycle that CheckNoSizeCycle checks for  and execute ifnok (default FailAlignSizeWarn) if this is the case. Motivation is that removing will result in the computation graph being in an invalid state as one of  the vertices must fulfill the impossible criterion nout(v) == nout(v) + a where a > 0.\n\nIf no such cycle is detected, then proceed to execute strategy ifok (default IncreaseSmaller).\n\nWill check both at prealignsizes (i.e before edge is added) and at postalignsizes (i.e after edge is added).\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#Internal-functions-with-doc-strings","page":"Internal functions with doc strings","title":"Internal functions with doc strings","text":"","category":"section"},{"location":"reference/internal/internal/","page":"Internal functions with doc strings","title":"Internal functions with doc strings","text":"These are not part of the public API.","category":"page"},{"location":"reference/internal/internal/#NaiveNASlib.JuMPNorm","page":"Internal functions with doc strings","title":"NaiveNASlib.JuMPNorm","text":"JuMPNorm\n\nAbstract type for norms to a JuMP model.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.sizeobjective!","page":"Internal functions with doc strings","title":"NaiveNASlib.sizeobjective!","text":"sizeobjective!(case, s::AbstractJuMPΔSizeStrategy, model, noutvars, sizetargets)\n\nAdd the objective for noutvars using strategy s.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.solve_outputs_selection","page":"Internal functions with doc strings","title":"NaiveNASlib.solve_outputs_selection","text":"solve_outputs_selection(s::AbstractΔSizeStrategy, vertices::AbstractVector{<:AbstractVertex}, utilityfun)\n\nReturns a tuple (success, nindict, noutdict) where nindict[vi] are new input neuron indices and noutdict[vi] are new output neuron indices for each vertex vi in vertices.\n\nThe function generally tries to maximize sum(utilityfun(vi) .* selected[vi]) ∀ vi in vertices where selected[vi] is all elements in noutdict[vi] larger than 0 (negative values  in noutdict indicates a new output shall be inserted at that position). This however is up to the implementation of the AbstractΔSizeStrategy s.\n\nSince selection of outputs is not guaranteed to work in all cases, a flag success is also returned. If success is false then applying the new indices may (and probably will) fail.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.all_in_Δsize_graph","page":"Internal functions with doc strings","title":"NaiveNASlib.all_in_Δsize_graph","text":"all_in_Δsize_graph(v::AbstractVertex, d::Direction)\n\nReturn an array of vertices which will be affected if v changes size in direction d.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.noinsertgaps!","page":"Internal functions with doc strings","title":"NaiveNASlib.noinsertgaps!","text":"noinsertgaps!(model, select, insert, maxinsert=length(outsel) * 10)\n\nAdd constraints so that insert does not create undefined gaps in the result of the neuron selection.\n\nAssume select is a set of binary variables where select[i] = 1 means select the output neuron at position i  and insert[i] = N means insert N new output neurons at the position after i.\n\nAn example of an undefined gap is if select = [1, 1, 0] and insert = [0, 0, 1] because this results in the  instruction to use existing output neurons 1 and 2 and then insert a new neuron at position 4.  In this example position 3 is an undefined gap as one should neither put an existing neuron there nor shall one insert new neurons. Running this method constrains model so that this solution is infeasible.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.Both","page":"Internal functions with doc strings","title":"NaiveNASlib.Both","text":"Both\n\nRepresents both directions (Input and Output).\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.SizeAlignFailError","page":"Internal functions with doc strings","title":"NaiveNASlib.SizeAlignFailError","text":"SizeAlignFailError <: Exception\n\nSizes could not be aligned.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.neighbours","page":"Internal functions with doc strings","title":"NaiveNASlib.neighbours","text":"neighbours(d::Direction, v)\n\nReturn vertices connected to v in direction d.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.ΔSizeFailError","page":"Internal functions with doc strings","title":"NaiveNASlib.ΔSizeFailError","text":"ΔSizeFailError <: Exception\n\nSize change could not be solved.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.ninconstraint!","page":"Internal functions with doc strings","title":"NaiveNASlib.ninconstraint!","text":"ninconstraint!(case, s, v, data)\n\nAdd input size constraints for AbstractVertex v using strategy s.\n\nExtra info like the model and variables is provided in data.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.newsizes","page":"Internal functions with doc strings","title":"NaiveNASlib.newsizes","text":"newsizes(s::AbstractΔSizeStrategy, vertices::AbstractArray{<:AbstractVertex})\n\nReturn a vector of new outputs sizes for and a Dict of new input sizes for all provided vertices using the strategy s.\n\nResult vector is index aligned with vertices. Result Dict has a vector of input sizes for each element of vertices which has an input (i.e everything except input vertices).\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.Input","page":"Internal functions with doc strings","title":"NaiveNASlib.Input","text":"Input\n\nRepresents the input direction, i.e coming from the output of another vertex.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.L1NormLinear","page":"Internal functions with doc strings","title":"NaiveNASlib.L1NormLinear","text":"L1NormLinear\nL1NormLinear()\n\nAdd a set of linear constraints to a model to map an expression to a variable which is the L1 norm of that expression.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.SumNorm","page":"Internal functions with doc strings","title":"NaiveNASlib.SumNorm","text":"SumNorm{N<:JuMPNorm} <: JuMPNorm\n\nSum of ns.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.sizeconstraint!","page":"Internal functions with doc strings","title":"NaiveNASlib.sizeconstraint!","text":"sizeconstraint!(s::AbstractJuMPΔSizeStrategy, v, data)\n\nAdd size constraints for AbstractVertex v using strategy s.\n\nExtra info like the model and variables is provided in data.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.MaxNormLinear","page":"Internal functions with doc strings","title":"NaiveNASlib.MaxNormLinear","text":"MaxNormLinear\nMaxNormLinear()\n\nAdd a set of linear constraints to a model to map an expression to a variable which is the max norm of that expression.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.AlignNinToNoutVertices","page":"Internal functions with doc strings","title":"NaiveNASlib.AlignNinToNoutVertices","text":"AlignNinToNoutVertices{V1,V2,S,F} <: AbstractJuMPΔSizeStrategy\nAlignNinToNoutVertices(vin::V1, vout::V2, inds; vstrat::S=AlignNinToNout(), fallback::F=ΔSizeFailNoOp())\nAlignNinToNoutVertices(vin::V1, vout::V2, inds, vstrat::S, fallback::F)\n\nSame as AlignNinToNout with an additional constraint that nin(s.vin)[s.ininds] == nout(s.vout)  where s is a AlignNinToNoutVertices.\n\nUseful in the context of adding edges to vertices to align sizes before the edge has been added.\n\nIf it fails, the operation will be retried with the fallback strategy (default ΔSizeFailNoOp).\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.vertexconstraints!","page":"Internal functions with doc strings","title":"NaiveNASlib.vertexconstraints!","text":"vertexconstraints!(s::AbstractJuMPΔSizeStrategy, v, data)\n\nAdd constraints for AbstractVertex v using strategy s.\n\nExtra info like the model and variables is provided in data.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.opposite","page":"Internal functions with doc strings","title":"NaiveNASlib.opposite","text":"opposite(d::Direction)\n\nReturn the opposite direction of d.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.ScalarSize","page":"Internal functions with doc strings","title":"NaiveNASlib.ScalarSize","text":"ScalarSize\n\nTreat vertices as having a scalar size when formulating the size change problem.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.Output","page":"Internal functions with doc strings","title":"NaiveNASlib.Output","text":"Output\n\nRepresents the output direction, i.e coming from the input of another vertex.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.sizemodel","page":"Internal functions with doc strings","title":"NaiveNASlib.sizemodel","text":"sizemodel(s::AbstractJuMPΔSizeStrategy, vertices)\n\nReturn a JuMP.Model for executing strategy s on vertices.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.ScaleNorm","page":"Internal functions with doc strings","title":"NaiveNASlib.ScaleNorm","text":"ScaleNorm{S<:Real,N} <: JuMPNorm\nScaleNorm(scale, n)\n\nScales result from n with a factor scale.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.norm!","page":"Internal functions with doc strings","title":"NaiveNASlib.norm!","text":"norm!(s::L1NormLinear, model, X)\n\nAdd a set of linear constraints to a model to map X to an expression X′ which is the L1 norm of X.\n\nNote that it only works for the objective function and only for minimization.\n\n\n\n\n\nnorm!(s::L1NormLinear, model, X)\n\nAdd a set of linear constraints to a model to map X to a variable X′ which is the max norm of X.\n\nNote that it only works for the objective function and only for minimization.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.accept","page":"Internal functions with doc strings","title":"NaiveNASlib.accept","text":"accept(case, ::AbstractJuMPΔSizeStrategy, model::JuMP.Model)\n\nReturn true of the solution for model is accepted using strategy s.\n\n\n\n\n\n","category":"function"},{"location":"reference/internal/internal/#NaiveNASlib.NeuronIndices","page":"Internal functions with doc strings","title":"NaiveNASlib.NeuronIndices","text":"NeuronIndices\n\nTreat vertices as having parameters which represents neurons when formulating the size change problem.\n\nThis means that individual indices will be aligned so that the function to the largest extent possible is the same after resizing.\n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.ΔNoutMix","page":"Internal functions with doc strings","title":"NaiveNASlib.ΔNoutMix","text":"ΔNoutMix{VE, VR, F} <: AbstractJuMPΔSizeStrategy\nΔNoutMix(exact::ΔNout{Exact, VE, F}, relax::ΔNout{Relaxed, VR, F}, fallback::F)\n\nStrategy for changing nout of vertices.\n\nApplies both exact and relax, thereby allowing for having both hard and relaxed size constraints for different vertices.\n\nCan be conveniently created by ΔNout or ΔNin. \n\n\n\n\n\n","category":"type"},{"location":"reference/internal/internal/#NaiveNASlib.SizeCycleDetector.isinsizecycle","page":"Internal functions with doc strings","title":"NaiveNASlib.SizeCycleDetector.isinsizecycle","text":"isinsizecycle(v)\n\nReturn true if removing v leads to a size cycle.  \n\nA size cycle is when at least one vertex vi has the impossible size constraint that nout(vi) == nout(vi) + nout(vj) where vj is a vertex in the graph (possibly vi).\n\nThis tends to happen when concatenation is followed by an elementwise operation and removing one input vi to the concatenation and replacing it with another vertex vj  which is also input to the elementwise operation (possibly through any number of size transparent operations). Since the sum of input sizes to the concatenation must be  equal to the input size of the elementwise operation and one out of several inputs to the concatenation must also have the same output size as the input to the  elementwise operation we are stuck with an impossible constraint.\n\nAs the algorithm is a bit messy (which imo is a sign that it is incorrect), here is a rundown of the idea:\n\nFrom the queired vertex, trace the graph forwards (output direction) until we hit a non-SizeTransparent vertex. If we encounter a SizeStack vertex store \n\nthis vertex in a SeenSizeStack and use it as the current state. If we encounter a SizeInvariant when we have SeenSizeStack as the state, we will store the  vertex and the SeenSizeStack as the output. The result from this is thus the set of potentially problematic vertices. If there are no potentially problematic vertices there can not be a size cycle and we return false.\n\nAs the posed question is \"If I remove v and connect its inputs to its outputs, will there be a size cycle?\" we determine if shortcutting v creates a size transparent\n\npath between any input ancestor to v and any of the problematic vertices. To avoid having to check all ancestors, we just examine the set which terminates any size  transparency using findterminating, knowing that if v and a problematic vertex share such a terminating ancestor, then shortcutting v creates a size transparent path to the problematic vertex which may not have been there before. If there are no problematic vertices which share a common terminating ancestor with v we return false.\n\nFor each problematic vertex vp and associated set of terminating ancestors VPa which passes the check in 2 we now check if any of the vertices in VPa sees vp as\n\nproblematic for the same reason as v does, meaning that they both pass through the same concatenation at least one time before hitting vp. If not, it basically means  that v is alone in a noop concatenation and there is no vj from the first paragraph to create an impossible constraint. If this applies to all problematic vertices we don't have a size cycle and return false.\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/infixconf/#Element-Wise-Configuration","page":"Element Wise Configuration","title":"Element Wise Configuration","text":"","category":"section"},{"location":"reference/advanced/infixconf/","page":"Element Wise Configuration","title":"Element Wise Configuration","text":"These are only to be used before >> when creating element wise vertices through infix operators (e.g. +, * etc.).","category":"page"},{"location":"reference/advanced/infixconf/","page":"Element Wise Configuration","title":"Element Wise Configuration","text":"Imported to namespace by","category":"page"},{"location":"reference/advanced/infixconf/","page":"Element Wise Configuration","title":"Element Wise Configuration","text":"using NaiveNASlib.Advanced","category":"page"},{"location":"reference/advanced/infixconf/#NaiveNASlib.VertexConf","page":"Element Wise Configuration","title":"NaiveNASlib.VertexConf","text":"VertexConf\nVertexConf(; traitdecoration = identity, outwrap = identity)\n\nConfig struct to be used with element wise op syntax (+, -, *, /).\n\ntraitdecoration allows for decorating the vertex trait with stuff like logging, validation etc. outwrap is a function which returns a function which will be applied to the computed output.  For example, the following outwrap scales output by a factor of 2: outwrap = f ->  (x...) -> 2f((x...)\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/infixconf/#NaiveNASlib.traitconf","page":"Element Wise Configuration","title":"NaiveNASlib.traitconf","text":"traitconf(t)\n\nShortcut for VertexConf(;traitdecoration=t).\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/infixconf/#NaiveNASlib.outwrapconf","page":"Element Wise Configuration","title":"NaiveNASlib.outwrapconf","text":"outwrapconf(o)\n\nShortcut for VertexConf(;outwrap=o).\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/traits/#Extra-Vertex-Traits","page":"Extra Vertex Traits","title":"Extra Vertex Traits","text":"","category":"section"},{"location":"reference/advanced/traits/","page":"Extra Vertex Traits","title":"Extra Vertex Traits","text":"Imported to namespace by","category":"page"},{"location":"reference/advanced/traits/","page":"Extra Vertex Traits","title":"Extra Vertex Traits","text":"using NaiveNASlib.Advanced","category":"page"},{"location":"reference/advanced/traits/#NaiveNASlib.NamedTrait","page":"Extra Vertex Traits","title":"NaiveNASlib.NamedTrait","text":"NamedTrait <: DecoratingTrait\nNamedTrait(name, base)\n\nTrait which attaches name to a vertex. Calling name(v) on a vertex with this trait returns name.   \n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/traits/#NaiveNASlib.AfterΔSizeTrait","page":"Extra Vertex Traits","title":"NaiveNASlib.AfterΔSizeTrait","text":"AfterΔSizeTrait <: DecoratingTrait\nAfterΔSizeTrait(strategy::S, base::T)\n\nCalls after_Δnin(strategy, v, Δs, ischanged) and after_Δnout(strategy, v, Δ, ischanged) after a size change for the vertex v which this trait is attached to.\n\n\n\n\n\n","category":"type"},{"location":"reference/advanced/traits/#NaiveNASlib.named","page":"Extra Vertex Traits","title":"NaiveNASlib.named","text":"named(name)\n\nReturn a function t -> NamedTrait(name, t) intended to reduce a bit of the verbosity when using traitdecoration.\n\nIntended to be composable with other similar functions through ∘.\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/traits/#NaiveNASlib.logged","page":"Extra Vertex Traits","title":"NaiveNASlib.logged","text":"logged(args...;kwargs...)\n\nReturn a function t -> AfterΔSizeTrait(logafterΔsize(args...;kwargs...) indended to reduce a bit of the verbosity when using traitdecoration.\n\nIntended to be composable with other similar functions through ∘.\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/traits/#NaiveNASlib.validated","page":"Extra Vertex Traits","title":"NaiveNASlib.validated","text":"validated(args...;kwargs...)\n\nReturn a function t -> AfterΔSizeTrait(validateafterΔsize(args...;kwargs...), t) indended to reduce a bit of the verbosity when using traitdecoration.\n\nIntended to be composable with other similar functions through ∘.\n\n\n\n\n\n","category":"function"},{"location":"reference/extend/traits/#Trait-Types","page":"Trait Types","title":"Trait Types","text":"","category":"section"},{"location":"reference/extend/traits/","page":"Trait Types","title":"Trait Types","text":"Traits are very useful for reasoning about a vertex without having to look at the wrapped computation.","category":"page"},{"location":"reference/extend/traits/","page":"Trait Types","title":"Trait Types","text":"Imported to namespace by","category":"page"},{"location":"reference/extend/traits/","page":"Trait Types","title":"Trait Types","text":"using NaiveNASlib.Extend","category":"page"},{"location":"reference/extend/traits/#NaiveNASlib.trait","page":"Trait Types","title":"NaiveNASlib.trait","text":"trait(v)\n\nReturn the MutationTrait for a vertex v.\n\n\n\n\n\n","category":"function"},{"location":"reference/extend/traits/#NaiveNASlib.base-Tuple{DecoratingTrait}","page":"Trait Types","title":"NaiveNASlib.base","text":"base(t::DecoratingTrait)\n\nReturn the trait wrapped by t.\n\n\n\n\n\n","category":"method"},{"location":"reference/extend/traits/#NaiveNASlib.MutationTrait","page":"Trait Types","title":"NaiveNASlib.MutationTrait","text":"MutationTrait\n\nBase type for traits relevant when mutating.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/traits/#NaiveNASlib.DecoratingTrait","page":"Trait Types","title":"NaiveNASlib.DecoratingTrait","text":"DecoratingTrait <: MutationTrait\n\nAvbstract trait which wraps another trait. The wrapped trait of a DecoratingTrait t is accessible through base(t).\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/traits/#NaiveNASlib.Immutable","page":"Trait Types","title":"NaiveNASlib.Immutable","text":"Immutable\n\nTrait for vertices which are immutable. Typically inputs and outputs as those are fixed to the surroundings (e.g a data set).\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/traits/#NaiveNASlib.MutationSizeTrait","page":"Trait Types","title":"NaiveNASlib.MutationSizeTrait","text":"MutationSizeTrait\n\nBase type for mutation traits relevant to size\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/traits/#NaiveNASlib.SizeAbsorb","page":"Trait Types","title":"NaiveNASlib.SizeAbsorb","text":"SizeAbsorb\n\nSize trait type for which size changes are absorbed, i.e they do not propagate forward.\n\nNote that size changes do propagate backward as changing the input size of a vertex requires that the output size of its input is also changed and vice versa.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/traits/#NaiveNASlib.SizeTransparent","page":"Trait Types","title":"NaiveNASlib.SizeTransparent","text":"SizeTransparent\n\nBase type for mutation traits which are transparent w.r.t size, i.e size changes propagate both forwards and backwards.\n\nTip: Use with FixedSizeTrait if the function has parameters which must be aligned with the input and output sizes.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/traits/#NaiveNASlib.SizeStack","page":"Trait Types","title":"NaiveNASlib.SizeStack","text":"SizeStack\n\nTransparent size trait type where inputs are stacked, i.e output size is the sum of all input sizes.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/traits/#NaiveNASlib.SizeInvariant","page":"Trait Types","title":"NaiveNASlib.SizeInvariant","text":"SizeInvariant\n\nTransparent size trait type where all input sizes must be equal to the output size, e.g. elementwise operations (including broadcasted).\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/traits/#NaiveNASlib.FixedSizeTrait","page":"Trait Types","title":"NaiveNASlib.FixedSizeTrait","text":"FixedSizeTrait <: DecoratingTrait\n\nTrait which indicates that a vertex is SizeTransparent while still having a fixed size.\n\nThis prevents NaiveNASlib from inferring the size from neighbouring vertices.\n\nAs an example, the function x -> 2 .* x accepts any size of x, while the function x -> [1,2,3] .* x is SizeInvariant but has a fixed size of 3.\n\nNote that FixedSizeTrait does not imply that the vertex can't change size.\n\n\n\n\n\n","category":"type"},{"location":"reference/simple/queryvertex/#Access-vertex-data","page":"Access vertex data","title":"Access vertex data","text":"","category":"section"},{"location":"reference/simple/queryvertex/#NaiveNASlib.inputs-Tuple{AbstractVertex}","page":"Access vertex data","title":"NaiveNASlib.inputs","text":"inputs(v)\n\nReturn an Array of vertices which are input to the given vertex.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend\n\njulia> inputs(CompVertex(identity, InputVertex(1)))\n1-element Vector{AbstractVertex}:\n InputVertex(1)\n\n\n\n\n\n","category":"method"},{"location":"reference/simple/queryvertex/#NaiveNASlib.outputs-Tuple{AbstractVertex}","page":"Access vertex data","title":"NaiveNASlib.outputs","text":"outputs(v)\n\nReturn an Array of vertices for which the given vertex is input to.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> iv = inputvertex(\"in\", 3);\n\njulia> cv = invariantvertex(identity, iv);\n\njulia> outputs(iv)\n1-element Vector{NaiveNASlib.AbstractVertex}:\n MutationVertex(CompVertex(identity, inputs=[in], outputs=[]), NaiveNASlib.SizeInvariant()) \n\n\n\n\n\n","category":"method"},{"location":"reference/simple/queryvertex/#NaiveNASlib.nin","page":"Access vertex data","title":"NaiveNASlib.nin","text":"nin(v)\n\nReturn the number of input neurons of vertex v. \n\nThis is typically the number of rows/columns of a parameter Matrix for fully connected layers or the number of input channels in a convolutional layer. \n\nNote that NaiveNASlib does not have the capability to figure this out by itself so this must be provided by the function wrapped in the vertex. For SizeTransparent vertices, NaiveNASlib will default to computing nin(v) from the sizes of the inputs.\n\nThere are three ways to implement nin for a function/callable f of type F:\n\n1. nin(f::F)\n2. nin(st::ST, f) and st = shapetrait(f)\n3. nin(f::F, t::MutationTrait, v::AbstractVertex)\n\nWhile 1 is the most straight forward, 2 can be useful of there are many different fs which happen to share a common method for determining the size. Option 3 is when the implementation might want to use other information from v or t and is left as an escape hatch.\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/queryvertex/#NaiveNASlib.nout","page":"Access vertex data","title":"NaiveNASlib.nout","text":"nout(v)\n\nReturn the number of output neurons of vertex v. \n\nThis is typically the number of rows/columns of a parameter Matrix for fully connected layers or the number of output channels in a convolutional layer. \n\nNote that NaiveNASlib does not have the capability to figure this out by itself so this must be provided by the function wrapped in the vertex. For SizeTransparent vertices, NaiveNASlib will default to computing nout(v) from the sizes of the inputs.\n\nThere are three ways to implement nin for a function/callable f of type F:\n\n1. nout(f::F)\n2. nout(st::ST, f) and st = shapetrait(f)\n3. nout(f::F, t::MutationTrait, v::AbstractVertex)\n\nWhile 1 is the most straight forward, 2 can be useful of there are many different fs which happen to share a common method for determining the size. Option 3 is when the implementation might want to use other information from v or t and is left as an escape hatch.\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/queryvertex/#NaiveNASlib.name","page":"Access vertex data","title":"NaiveNASlib.name","text":"name(v)\n\nReturn a the name of the vertex v.  Will return a generic string describing v if no name has been given to v. \n\nNote that names in a graph don't have to be unique. \n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#Vertex-Creation","page":"Vertex Creation","title":"Vertex Creation","text":"","category":"section"},{"location":"reference/simple/createvertex/#NaiveNASlib.inputvertex","page":"Vertex Creation","title":"NaiveNASlib.inputvertex","text":"inputvertex(name, size)\n\nReturn an immutable input type vertex with the given name and size.\n\nTypically used as \"entry\" point to a computation graph.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> inputvertex(\"input\", 5)\nInputSizeVertex(InputVertex(input, outputs=[]), 5)\n\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#NaiveNASlib.immutablevertex","page":"Vertex Creation","title":"NaiveNASlib.immutablevertex","text":"immutablevertex(computation, inputs::AbstractVertex...; traitdecoration=identity)\nimmutablevertex(vname::AbstractString, computation, inputs::AbstractVertex...; traitdecoration=identity)\nimmutablevertex(computation, vname::AbstractString, inputs::AbstractVertex...; traitdecoration=identity)\n\nReturn an immutable computation type vertex.\n\nUse traitdecoration to attach other traits, such as named, logged or validated.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = immutablevertex(x -> x * [1 2 3; 4 5 6], inputvertex(\"input\", 2));\n\njulia> v([1 2])\n1×3 Matrix{Int64}:\n 9  12  15\n\njulia> v = immutablevertex(\"v\", x -> x * [1 2 3; 4 5 6], inputvertex(\"input\", 2));\n\njulia> name(v)\n\"v\"\n\njulia> v = immutablevertex(\"v\", inputvertex(\"input\", 2)) do x\n           x * [1 2 3; 4 5 6]\n       end;\n\njulia> name(v)\n\"v\"       \n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#NaiveNASlib.absorbvertex","page":"Vertex Creation","title":"NaiveNASlib.absorbvertex","text":"absorbvertex(computation, inputs::AbstractVertex...; traitdecoration=identity)\nabsorbvertex(vname::AbstractString, computation, inputs::AbstractVertex...; traitdecoration=identity)\nabsorbvertex(computation, vname::AbstractString, inputs::AbstractVertex...; traitdecoration=identity)\n\nReturn a mutable computation type vertex which absorbs size changes. Typical example of this is a neural network layer wrapping a parameter array.\n\nUse traitdecoration to attach other traits, such as named, logged or validated.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = absorbvertex(x -> x * [1 2 3; 4 5 6], inputvertex(\"input\", 2));\n\njulia> v([1 2])\n1×3 Matrix{Int64}:\n 9  12  15\n\njulia> v = absorbvertex(\"v\", x -> x * [1 2 3; 4 5 6], inputvertex(\"input\", 2));\n\njulia> name(v)\n\"v\"\n\njulia> v = absorbvertex(\"v\", inputvertex(\"input\", 2)) do x\n           x * [1 2 3; 4 5 6]\n       end;\n\njulia> name(v)\n\"v\"       \n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#NaiveNASlib.invariantvertex","page":"Vertex Creation","title":"NaiveNASlib.invariantvertex","text":"invariantvertex(computation, inputs::AbstractVertex...; traitdecoration=identity)\ninvariantvertex(vname::AbstractString, computation, inputs::AbstractVertex...; traitdecoration=identity)\ninvariantvertex(computation, vname::AbstractString, inputs::AbstractVertex...; traitdecoration=identity)\n\nReturn a mutable computation type vertex which is size invariant, i.e nin == nout.\n\nUse traitdecoration to attach other traits, such as named, logged or validated.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = invariantvertex(x -> 2 .* x, inputvertex(\"input\", 2));\n\njulia> nin(v)\n1-element Vector{Int64}:\n 2\n\njulia> nout(v)\n2\n\njulia> v([1 2])\n1×2 Matrix{Int64}:\n 2  4\n\njulia> v = invariantvertex(\"v\", x -> 2 .* x, inputvertex(\"input\", 2));\n\njulia> name(v)\n\"v\"\n\njulia> v = invariantvertex(\"v\", inputvertex(\"input\", 2)) do x\n           2 .* x\n       end;\n\njulia> name(v)\n\"v\"    \n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#NaiveNASlib.conc","page":"Vertex Creation","title":"NaiveNASlib.conc","text":"conc(v::AbstractVertex, vs::AbstractVertex...; dims, traitdecoration=identity, outwrap=identity)\nconc(vname::AbstractString, v::AbstractVertex, vs::AbstractVertex...; dims, traitdecoration=identity, outwrap=identity)\n\nReturn a mutable vertex which concatenates input along dimension dim.\n\nUse traitdecoration to attach other traits, such as named, logged or validated.\n\nUse outwrap=f to wrap the concatenation function in f.\n\nconc(vname::AbstractString,...;traitdecoration = f, ...) is equivalent to conc(...;traitdecoration=named(vname) ∘ f, ...).\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = conc(inputvertex.([\"in1\", \"in2\", \"in3\"], 1:3)..., dims=1);\n\njulia> nin(v)\n3-element Vector{Int64}:\n 1\n 2\n 3\n\njulia> nout(v)\n6\n\njulia> v([1], [2, 3], [4, 5, 6])\n6-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n 6\n\njulia> v = conc(inputvertex.([\"in1\", \"in2\", \"in3\"], 1:3)..., dims=1, outwrap = f -> (x...) -> 2f(x...));\n \njulia> v([1], [2, 3], [4, 5, 6])\n6-element Vector{Int64}:\n  2\n  4\n  6\n  8\n 10\n 12\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#Base.:+","page":"Vertex Creation","title":"Base.:+","text":"+(v::AbstractVertex, vs::AbstractVertex...)\n\nReturn a mutable vertex which performs (broadcasted) elementwise addition of its inputs.\n\nAn AbstractString, Function or VertexConf can be supplied through the >> operator.  An AbstractString will be used as the name of the vertex, a Function f will wrap the  output so that the vertex computation becomes f(+.(x...)) and VertexConf can be used to supply both a name and a function.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = inputvertex(\"in1\", 2) + inputvertex(\"in2\", 2) + inputvertex(\"in3\" ,2);\n\njulia> nin(v)\n3-element Vector{Int64}:\n 2\n 2\n 2\n\njulia> nout(v)\n2\n\njulia> v([1, 2], [3, 4], [5, 6])\n2-element Vector{Int64}:\n  9\n 12\n\njulia> v = \"v\" >> inputvertex(\"in1\", 3) + inputvertex(\"in2\", 3);\n\njulia> name(v)\n\"v\"\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#Base.:-","page":"Vertex Creation","title":"Base.:-","text":"-(v1::AbstractVertex, v2::AbstractVertex)\n\nReturn a mutable vertex which performs (broadcasted) elementwise subtraction of its inputs.\n\nAn AbstractString, Function or VertexConf can be supplied through the >> operator.  An AbstractString will be used as the name of the vertex, a Function f will wrap the  output so that the vertex computation becomes f(-.(x...)) and VertexConf can be used to supply both a name and a function.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = inputvertex(\"in1\", 2) - inputvertex(\"in2\", 2);\n\njulia> nin(v)\n2-element Vector{Int64}:\n 2\n 2\n\njulia> nout(v)\n2\n\njulia> v([1, 2], [3, 4])\n2-element Vector{Int64}:\n -2\n -2\n\n\njulia> v = \"v\" >> inputvertex(\"in1\", 3) - inputvertex(\"in2\", 3);\n\njulia> name(v)\n\"v\"\n\n\n\n\n\n-(v::AbstractVertex)\n\nReturn a mutable vertex which performs elementwise negation of its input.\n\nAn AbstractString, Function or VertexConf can be supplied through the >> operator.  An AbstractString will be used as the name of the vertex, a Function f will wrap the  output so that the vertex computation becomes f(-.(x...)) and VertexConf can be used to supply both a name and a function. Due to operator precedence, this has to be done in the following order: -(conf >> v)\n\n#Examples\n\njulia> using NaiveNASlib\n\njulia> v = -inputvertex(\"in\", 2);\n\njulia> v([1,2])\n2-element Vector{Int64}:\n -1\n -2\n\njulia> v = -(\"v\" >> inputvertex(\"in\", 2));\n\njulia> name(v)\n\"v\"\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#Base.:*","page":"Vertex Creation","title":"Base.:*","text":"*(v::AbstractVertex, vs::AbstractVertex...)\n*(conf::VertexConf, v::AbstractVertex, vs::AbstractVertex...)\n\nReturn a mutable vertex which performs (broadcasted) elementwise multiplication of its inputs.\n\nAn AbstractString, Function or VertexConf can be supplied through the >> operator.  An AbstractString will be used as the name of the vertex, a Function f will wrap the  output so that the vertex computation becomes f(*.(x...)) and VertexConf can be used to supply both a name and a function.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = inputvertex(\"in1\", 2) * inputvertex(\"in2\", 2) * inputvertex(\"in3\" ,2);\n\njulia> nin(v)\n3-element Vector{Int64}:\n 2\n 2\n 2\n\njulia> nout(v)\n2\n\njulia> v([1, 2], [3, 4], [5, 6])\n2-element Vector{Int64}:\n 15\n 48\n\njulia> v = \"v\" >> inputvertex(\"in1\", 3) * inputvertex(\"in2\", 3);\n\njulia> name(v)\n\"v\"\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#Base.:/","page":"Vertex Creation","title":"Base.:/","text":"/(v1::AbstractVertex, v2::AbstractVertex)\n/(conf::VertexConf, v1::AbstractVertex, v2::AbstractVertex)\n\nReturn a mutable vertex which performs (broadcasted) elementwise division of its inputs.\n\nAn AbstractString, Function or VertexConf can be supplied through the >> operator.  An AbstractString will be used as the name of the vertex, a Function f will wrap the  output so that the vertex computation becomes f(/.(x...)) and VertexConf can be used to supply both a name and a function.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v = inputvertex(\"in1\", 2) / inputvertex(\"in2\", 2);\n\njulia> nin(v)\n2-element Vector{Int64}:\n 2\n 2\n\njulia> nout(v)\n2\n\njulia> v([6, 8], [2, 4])\n2-element Vector{Float64}:\n 3.0\n 2.0\n\njulia> v = \"v\" >> inputvertex(\"in1\", 3) / inputvertex(\"in2\", 3);\n\njulia> name(v)\n\"v\"\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/createvertex/#Base.:>>","page":"Vertex Creation","title":"Base.:>>","text":">>(conf::VertexConf, v::AbstractVertex)\n>>(name::AbstractString, v::AbstractVertex)\n>>(outwrap::Function, v::AbstractVertex)\n\nReturn inputs as a tuple. Only used to enable the conf >> v1 op v2 ... syntax.\n\n\n\n\n\n","category":"function"},{"location":"examples/advancedtutorial/#Advanced-Tutorial","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"","category":"section"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"The previous examples have been focused on giving an overview of the purpose of this library using the simple high level API. For more advanced usage, there are many of ways to customize the behavior and in other ways alter or hook in to the functionality. Some of the more important concepts are described below.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"To make it more convenient to extend NaiveNASlib, the two submodules NaiveNASlib.Advanced and NaiveNASlib.Extend export most of the useful stuff, such as abstract types and composable strategies. For now they are also part of the public API, but in future releases they might be moved to separate subpackages so that they can be versioned separately (e.g NaiveNASlibCore).","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"using NaiveNASlib.Advanced, NaiveNASlib.Extend","category":"page"},{"location":"examples/advancedtutorial/#Strategies","page":"Advanced Tutorial","title":"Strategies","text":"","category":"section"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"For more or less all operations which mutate the graph, it is possible achieve fine grained control of the operation through selecting a strategy.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Here is an example of strategies for changing the size.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"First we make a simple graph where one vertex has a constraint for changing the size.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"invertex = inputvertex(\"in\", 3)\nlayer1 = linearvertex(invertex, 4)\njoined = conc(scalarmult(layer1, 2), scalarmult(layer1, 3), dims=1)","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Note that joined can only change in steps of 2.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Strategy to try to change it by one and throw an error when not successful.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"exact_or_fail = ΔNoutExact(joined => 1; fallback=ThrowΔSizeFailError(\"Size change failed!!\"))","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Note that we now call Δsize! instead of Δnout! as the wanted action is given by the strategy.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"@test_throws NaiveNASlib.ΔSizeFailError Δsize!(exact_or_fail)\n@test nout(joined) == 2*nout(layer1) == 8 # No change was made.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Try to change by one and fail silently when not successful.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"exact_or_noop = ΔNoutExact(joined=>1;fallback=ΔSizeFailNoOp())\n\n@test !Δsize!(exact_or_noop)\n@test nout(joined) == 2*nout(layer1) == 8 # No change was made.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"In many cases it is ok to not get the exact change which was requested.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"relaxed_or_fail = ΔNoutRelaxed(joined=>1;fallback=ThrowΔSizeFailError(\"This should not happen!!\"))\n\n@test Δsize!(relaxed_or_fail)\n# Changed by two as this was the smallest possible change.\n@test nout(joined) == 2*nout(layer1) == 10","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Logging when fallback is applied is also possible.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"using Logging: Info\nexact_or_log_then_relax = ΔNoutExact(joined=>1;\n                                        fallback=LogΔSizeExec(\n                                                        \"Exact failed, relaxing\",\n                                                        Info,\n                                                        relaxed_or_fail))\n\n@test_logs (:info, \"Exact failed, relaxing\") Δsize!(exact_or_log_then_relax)\n@test nout(joined) == 2*nout(layer1) == 12","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"If one wants to see every size change we can set up an AfterΔSizeCallback strategy to log it for us like this:","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"exact_or_log_then_relax_verbose = logafterΔsize(v -> \"some vertex\";base=exact_or_log_then_relax)\n\n@test_logs(\n    (:info, \"Exact failed, relaxing\"),\n    (:info, r\"Change nin of some vertex\"),\n    (:info, r\"Change nout of some vertex\"),\n    match_mode=:any,\n    Δsize!(exact_or_log_then_relax_verbose))","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"A similar pattern is used for most other mutating operations. See the advanced reference documentation for the complete set.","category":"page"},{"location":"examples/advancedtutorial/#Traits","page":"Advanced Tutorial","title":"Traits","text":"","category":"section"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"A variant (bastardization?) of the holy trait pattern is used to annotate the type of a vertex. The core idea is discussed a bit in the Terminology section, but it is also possible to attach other information and behaviors by freeriding on this mechanism.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"This is done by adding the argument traitdecoration when creating a vertex and supplying a function which takes a trait and return a new trait (which typically wraps the input).","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Naming vertices is so useful for logging and debugging I almost made it mandatory.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"If a vertex does not have the named trait, name will return a generic string. Compare","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"noname = linearvertex(inputvertex(\"in\", 2), 2)\n@test name(noname) == \"MutationVertex::SizeAbsorb\"","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"with","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"hasname = absorbvertex(LinearLayer(2, 3), inputvertex(\"in\", 2), traitdecoration = t -> NamedTrait(\"named layer\", t))\n@test name(hasname) == \"named layer\"","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"which is basically what the convenience methods do under the hood.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"hasnametoo = absorbvertex(\"also named\", LinearLayer(2, 3), inputvertex(\"in\", 2))\n@test name(hasnametoo) == \"also named\"","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"AfterΔSizeTrait can be used to attach an AbstractAfterΔSizeStrategy to an individual vertex. In this case we use logafterΔsize from the example above.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"verbose_vertex_info(v) = string(name(v),\n                                 \" with inputs=[\", join(name.(inputs(v)),  \", \"),\n                                \"] and outputs=[\", join(name.(outputs(v)), \", \"), ']')\nnamed_verbose_logging(t) = AfterΔSizeTrait(\n                                        logafterΔsize(verbose_vertex_info),\n                                        NamedTrait(\"layer1\", t))\nlayer1 = absorbvertex(  LinearLayer(2, 3),\n                        inputvertex(\"in\", 2),\n                        traitdecoration = named_verbose_logging)","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"The above is a mouthful, but NaiveNASlib.Advanced exports the named and logged functions for convenience","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"layer2 = absorbvertex(  LinearLayer(nout(layer1), 4),\n                        layer1;\n                        traitdecoration = logged(name) ∘ named(\"layer2\"))","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Now logs for layer2 are less verbose than logs for layer1 due to name being used to print the vertex instead of verbose_vertex_info.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"@test_logs(\n(:info, \"Change nout of layer1 with inputs=[in] and outputs=[layer2] by [1, 2, 3, -1]\"),\n(:info, \"Change nin of layer2 by [1, 2, 3, -1]\"),\nΔnout!(layer1, 1))","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"For more elaborate traits with elementwise operations one can use traitconf and >>.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"add = traitconf(logged(verbose_vertex_info) ∘ named(\"layer1+layer2\")) >> layer1 + layer2\n@test name(add) == \"layer1+layer2\"\n\n@test_logs(\n(:info, \"Change nout of layer1 with inputs=[in] and outputs=[layer2, layer1+layer2] by [1, 2, 3, 4, -1]\"),\n(:info, \"Change nin of layer2 by [1, 2, 3, 4, -1]\"),\n(:info, \"Change nout of layer2 by [1, 2, 3, 4, -1]\"),\n(:info, \"Change nin of layer1+layer2 with inputs=[layer1, layer2] and outputs=[] by [1, 2, 3, 4, -1] and [1, 2, 3, 4, -1]\"),\n(:info, \"Change nout of layer1+layer2 with inputs=[layer1, layer2] and outputs=[] by [1, 2, 3, 4, -1]\"),\nΔnout!(layer1, 1))","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"When creating own trait wrappers, remember to subtype DecoratingTrait or else there will be pain.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"struct PainfulTrait{T<:MutationTrait} <: MutationTrait\n    base::T\nend\npainlayer = absorbvertex(   LinearLayer(2, 3),\n                            inputvertex(\"in\", 2);\n                            traitdecoration = PainfulTrait)","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Wrong! Not a subtype of DecoratingTrait.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"@test_throws MethodError Δnout!(painlayer, 1)","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Now one must implement a lot of methods for PainfulTrait...","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Lets try that again:","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"struct SmoothSailingTrait{T<:MutationTrait} <: DecoratingTrait\n    base::T\nend","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Right! Is a subtype of DecoratingTrait. Just implement base and all will be fine.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"NaiveNASlib.base(t::SmoothSailingTrait) = t.base\n\nsmoothlayer = absorbvertex( LinearLayer(2, 3),\n                            inputvertex(\"in\", 2);\n                            traitdecoration = SmoothSailingTrait)\n\n@test Δnout!(smoothlayer, 1)\n@test nout(smoothlayer) == 4","category":"page"},{"location":"examples/advancedtutorial/#Graph-instrumentation-and-modification","page":"Advanced Tutorial","title":"Graph instrumentation and modification","text":"","category":"section"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"In many cases it is desirable to change things like traits of an existing graph. This can be achieved through Functors.jl, often through clever usage of the walk function.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Depending on what one wants to achieve, it can be more or less messy. Here is a pretty messy example:","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"invertex = inputvertex(\"in\", 2)\nlayer1 = linearvertex(invertex, 3)\nlayer2 = linearvertex(layer1, 4)\n\ngraph = CompGraph(invertex, layer2)\n\n@test name.(vertices(graph)) == [\"in\", \"MutationVertex::SizeAbsorb\", \"MutationVertex::SizeAbsorb\"]","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Ok, lets add names to layer1 and layer2 and change the name of invertex by using Functors.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"import Functors\n\nstruct RenameWalk <: Functors.AbstractWalk end","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Always used CachedWalk on CompGraphs and vertices!!","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"walk = Functors.CachedWalk(RenameWalk())","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Add a name to layer1 and layer2","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"function (::RenameWalk)(recurse, v::MutationVertex)\n    # This is probably not practical to do in a real graph, so make sure you have names when first creating it...\n    name = v == layer1 ? \"layer1\" : \"layer2\"\n    addname(x) = x\n    # SizeAbsorb has no fields, otherwise we would have had to use walk to wrap it\n    addname(t::SizeAbsorb) = NamedTrait(name, t)\n    Functors.DefaultWalk()(v) do x\n        Functors.fmap(addname, x; walk, cache=nothing)\n    end\nend","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Change name of invertex once we get there. We could also just have made a string version of addname above since there are no other strings in the graph, but this is safer.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"function (::RenameWalk)(recurse, v::InputVertex)\n    rename(x) = x\n    rename(s::String) = \"in changed\"\n    Functors.DefaultWalk()(v) do x\n        Functors.fmap(rename, x; walk, cache=nothing)\n    end\nend","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"Everything else just gets functored as normal.","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"(::RenameWalk)(recurse, x) = Functors.DefaultWalk()(recurse, x)","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"I must admit that thinking about what this does makes me a bit dizzy...","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"namedgraph = Functors.execute(walk, graph)\n\n@test name.(vertices(namedgraph)) == [\"in changed\", \"layer1\", \"layer2\"]\n@test graph(ones(2, 1)) == namedgraph(ones(2,1))","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"","category":"page"},{"location":"examples/advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/extend/strategies/#Strategy-Base-Types","page":"Strategy Base Types","title":"Strategy Base Types","text":"","category":"section"},{"location":"reference/extend/strategies/","page":"Strategy Base Types","title":"Strategy Base Types","text":"Useful when implementing new strategies.","category":"page"},{"location":"reference/extend/strategies/","page":"Strategy Base Types","title":"Strategy Base Types","text":"Imported to namespace by","category":"page"},{"location":"reference/extend/strategies/","page":"Strategy Base Types","title":"Strategy Base Types","text":"using NaiveNASlib.Extend","category":"page"},{"location":"reference/extend/strategies/#NaiveNASlib.AbstractΔSizeStrategy","page":"Strategy Base Types","title":"NaiveNASlib.AbstractΔSizeStrategy","text":"AbstractΔSizeStrategy\n\nAbstract base type for strategies for how to change the size.\n\nSee Δsize!.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/strategies/#NaiveNASlib.AbstractJuMPΔSizeStrategy","page":"Strategy Base Types","title":"NaiveNASlib.AbstractJuMPΔSizeStrategy","text":"AbstractJuMPΔSizeStrategy <: AbstractΔSizeStrategy\n\nAbstract type for strategies to change or align the sizes of vertices using JuMP.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/strategies/#NaiveNASlib.DecoratingJuMPΔSizeStrategy","page":"Strategy Base Types","title":"NaiveNASlib.DecoratingJuMPΔSizeStrategy","text":"DecoratingJuMPΔSizeStrategy <: AbstractJuMPΔSizeStrategy\n\nAbstract type for AbstractJuMPΔSizeStrategies which wants to delegate some parts of the problem formulation to another strategy.\n\nMore concretely: If s is a DecoratingJuMPΔSizeStrategy then base(s) will be used unless explicitly stated through dispatch.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/strategies/#NaiveNASlib.base-Tuple{DecoratingJuMPΔSizeStrategy}","page":"Strategy Base Types","title":"NaiveNASlib.base","text":"base(s::DecoratingJuMPΔSizeStrategy)\n\nReturn the strategy wrapped by s.\n\n\n\n\n\n","category":"method"},{"location":"reference/extend/strategies/#NaiveNASlib.AbstractAfterΔSizeStrategy","page":"Strategy Base Types","title":"NaiveNASlib.AbstractAfterΔSizeStrategy","text":"AbstractAfterΔSizeStrategy <: DecoratingJuMPΔSizeStrategy\n\nAbstract base type for strategies which perform actions after size has changed (e.g validation and logging).\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/strategies/#NaiveNASlib.AbstractAlignSizeStrategy","page":"Strategy Base Types","title":"NaiveNASlib.AbstractAlignSizeStrategy","text":"AbstractAlignSizeStrategy\n\nBase type for strategies for how to align size (nin/nout) when doing structural mutation.\n\nNote that all strategies are not guaranteed to work in all cases.\n\nDefault strategies should however be selected based on case so that things always work out.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/strategies/#NaiveNASlib.AbstractConnectStrategy","page":"Strategy Base Types","title":"NaiveNASlib.AbstractConnectStrategy","text":"AbstractConnectStrategy\n\nBase type for strategies for how to (re)connect vertices when doing structural mutation.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/vertices/#Vertex-Types","page":"Vertex Types","title":"Vertex Types","text":"","category":"section"},{"location":"reference/extend/vertices/","page":"Vertex Types","title":"Vertex Types","text":"While it is not generally expected that implementations should need to define new vertex types, the existing ones are typically useful for dispatching.","category":"page"},{"location":"reference/extend/vertices/","page":"Vertex Types","title":"Vertex Types","text":"Imported to namespace by","category":"page"},{"location":"reference/extend/vertices/","page":"Vertex Types","title":"Vertex Types","text":"using NaiveNASlib.Extend","category":"page"},{"location":"reference/extend/vertices/#NaiveNASlib.base-Tuple{AbstractVertex}","page":"Vertex Types","title":"NaiveNASlib.base","text":"base(v::AbstractVertex)\n\nReturn the vertex wrapped in v (if any).\n\n\n\n\n\n","category":"method"},{"location":"reference/extend/vertices/#NaiveNASlib.AbstractVertex","page":"Vertex Types","title":"NaiveNASlib.AbstractVertex","text":"AbstractVertex\n\nVertex base type.\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/vertices/#NaiveNASlib.InputVertex","page":"Vertex Types","title":"NaiveNASlib.InputVertex","text":"InputVertex\n\nActs as a source of data to the graph and therefore does not need any input vertices to feed it.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend\n\njulia> InputVertex(1)\nInputVertex(1)\n\njulia> InputVertex(\"input\")\nInputVertex(input)\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/vertices/#NaiveNASlib.InputSizeVertex","page":"Vertex Types","title":"NaiveNASlib.InputSizeVertex","text":"InputSizeVertex\n\nVertex with an (immutable) size.\n\nIntended use is for wrapping an InputVertex in conjuntion with mutation\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/vertices/#NaiveNASlib.CompVertex","page":"Vertex Types","title":"NaiveNASlib.CompVertex","text":"CompVertex\nCompVertex(c, ins::AbstractVertex...)\nCompVertex(c, ins::AbstractArray{<:AbstractVertex}) =\n\nMaps input from input vertices to output through output = c(input...). \n\nMust have at least one input vertex.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Extend\n\njulia> CompVertex(+, InputVertex(1), InputVertex(2))\nCompVertex(+, inputs=[InputVertex(1), InputVertex(2)])\n\njulia> CompVertex(x -> 4x, InputVertex(1))(2)\n8\n\njulia> CompVertex(*, InputVertex(1), InputVertex(2))(2,3)\n6\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/vertices/#NaiveNASlib.MutationVertex","page":"Vertex Types","title":"NaiveNASlib.MutationVertex","text":"MutationVertex\n\nVertex which may be subject to mutation.\n\nThe member trait describes the nature of the vertex itself, for example if size changes are absorbed (e.g changing an nin x nout matrix to an nin - Δ x nout matrix) or if they propagate to neighbouring vertices (and if so, how).\n\n\n\n\n\n","category":"type"},{"location":"reference/extend/vertices/#NaiveNASlib.OutputsVertex","page":"Vertex Types","title":"NaiveNASlib.OutputsVertex","text":"OutputsVertex\n\nDecorates an AbstractVertex with output edges.\n\n\n\n\n\n","category":"type"},{"location":"reference/simple/graph/#Graph-Operations","page":"Graph Operations","title":"Graph Operations","text":"","category":"section"},{"location":"reference/simple/graph/#NaiveNASlib.CompGraph","page":"Graph Operations","title":"NaiveNASlib.CompGraph","text":"CompGraph\nCompGraph(input::AbstractVertex, output::AbstractVertex)\nCompGraph(input::AbstractVector{<:AbstractVertex}, output::AbstractVertex)\nCompGraph(input::AbstractVertex, output::AbstractVector{<:AbstractVertex})\n\nBasic graph for computation. While not strictly neccessary to compute anything, it makes it easier to keep track of things.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> v1 = inputvertex(\"in1\", 1) + inputvertex(\"in2\", 1);\n\njulia> v2 = invariantvertex(x -> 3x, v1);\n\njulia> CompGraph(inputs(v1), v2)(2,3) # (2 + 3) * 3\n15\n\njulia> CompGraph(inputs(v1), [v1, v2])(2,3)\n(5, 15)\n\n\n\n\n\n","category":"type"},{"location":"reference/simple/graph/#NaiveNASlib.inputs-Tuple{CompGraph}","page":"Graph Operations","title":"NaiveNASlib.inputs","text":"inputs(g::CompGraph)\n\nReturn the inputs vertices of g.\n\n\n\n\n\n","category":"method"},{"location":"reference/simple/graph/#NaiveNASlib.outputs-Tuple{CompGraph}","page":"Graph Operations","title":"NaiveNASlib.outputs","text":"outputs(g::CompGraph)\n\nReturn the output vertices of g.\n\n\n\n\n\n","category":"method"},{"location":"reference/simple/graph/#NaiveNASlib.vertices","page":"Graph Operations","title":"NaiveNASlib.vertices","text":"vertices(g::CompGraph)\n\nReturn an topologically sorted array of all vertices in the graph g.\n\nExamples\n\njulia> ins = InputVertex.(1:2);\n\njulia> v1 = CompVertex(+, ins...);\n\njulia> v2 = CompVertex(*, v1, ins[2]);\n\njulia> graph = CompGraph(ins, v2);\n\njulia> vertices(graph)\n4-element Array{AbstractVertex,1}:\n InputVertex(1)\n InputVertex(2)\n CompVertex(+), inputs=[InputVertex(1), InputVertex(2)]\n CompVertex(*), inputs=[CompVertex(+), InputVertex(2)]\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/graph/#NaiveNASlib.nvertices","page":"Graph Operations","title":"NaiveNASlib.nvertices","text":"nvertices(g::CompGraph)\n\nReturn the number of vertices in the graph.\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/graph/#NaiveNASlib.findvertices","page":"Graph Operations","title":"NaiveNASlib.findvertices","text":"findvertices(vname::AbstractString, g::CompGraph)\n\nReturn all vertices for which name(v) == vname`.\n\n\n\n\n\nfindvertices(vpat::Regex, g::CompGraph)\n\nReturn all vertices for which vpat matches name(v).\n\n\n\n\n\nfindvertices(predicate, g::CompGraph)\n\nReturn all vertices for which predicate(v) return true.\n\n\n\n\n\n","category":"function"},{"location":"reference/simple/graph/#NaiveNASlib.graphsummary","page":"Graph Operations","title":"NaiveNASlib.graphsummary","text":"graphsummary([io], graph, extracolumns...; [inputhl], [outputhl], kwargs...)\n\nPrints a summary table of graph to io using PrettyTables.pretty_table.\n\nExtra columns can be added to the table by providing any number of extracolumns which can be one of the following:\n\na function (or any callable object) which takes a vertex as input and returns the column content\na Pair where the first element is the column name and the other element is what previous bullet describes\n\nThe keyword arguments inputhl (default crayon\"fg:black bg:249\") and outputhl (default inputhl) can be used to set the highlighting of the inputs and outputs to graph respectively. If set to nothing no special highlighting will be used.\n\nAll other keyword arguments are forwarded to PrettyTables.pretty_table. Note that this allows for overriding the default formatting, alignment and highlighting.\n\nwarning: API Stability\nWhile this function is part of the public API for natural reasons, the exact shape of its output shall not be considered stable.Base.show for CompGraphs just calls this function. This might change in the future.\n\nExamples\n\njulia> using NaiveNASlib\n\njulia> g = let \n            v1 = \"v1\" >> inputvertex(\"in1\", 1) + inputvertex(\"in2\", 1)\n            v2 = invariantvertex(\"v2\", sin, v1)\n            v3 = conc(\"v3\", v1, v2; dims=1) \n            CompGraph(inputs(v1), v3)\n        end;\n\njulia> graphsummary(g)\n┌────────────────┬───────────┬────────────────┬───────────────────┐\n│ Graph Position │ Vertex Nr │ Input Vertices │ Op                │\n├────────────────┼───────────┼────────────────┼───────────────────┤\n│ Input          │ 1         │                │                   │\n│ Input          │ 2         │                │                   │\n│ Hidden         │ 3         │ 1,2            │ + (element wise)  │\n│ Hidden         │ 4         │ 3              │ sin               │\n│ Output         │ 5         │ 3,4            │ cat(x..., dims=1) │\n└────────────────┴───────────┴────────────────┴───────────────────┘\n\njulia> graphsummary(g, name, \"input sizes\" => nin, \"output sizes\" => nout)\n┌────────────────┬───────────┬────────────────┬───────────────────┬──────┬─────────────┬──────────────┐\n│ Graph Position │ Vertex Nr │ Input Vertices │ Op                │ Name │ input sizes │ output sizes │\n├────────────────┼───────────┼────────────────┼───────────────────┼──────┼─────────────┼──────────────┤\n│ Input          │ 1         │                │                   │ in1  │             │ 1            │\n│ Input          │ 2         │                │                   │ in2  │             │ 1            │\n│ Hidden         │ 3         │ 1,2            │ + (element wise)  │ v1   │ 1,1         │ 1            │\n│ Hidden         │ 4         │ 3              │ sin               │ v2   │ 1           │ 1            │\n│ Output         │ 5         │ 3,4            │ cat(x..., dims=1) │ v3   │ 1,1         │ 2            │\n└────────────────┴───────────┴────────────────┴───────────────────┴──────┴─────────────┴──────────────┘\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/graphquery/#Advanced-Graph-Functions","page":"Advanced Graph Functions","title":"Advanced Graph Functions","text":"","category":"section"},{"location":"reference/advanced/graphquery/","page":"Advanced Graph Functions","title":"Advanced Graph Functions","text":"Some more advanced functions for quering a graph.","category":"page"},{"location":"reference/advanced/graphquery/","page":"Advanced Graph Functions","title":"Advanced Graph Functions","text":"Imported to namespace by","category":"page"},{"location":"reference/advanced/graphquery/","page":"Advanced Graph Functions","title":"Advanced Graph Functions","text":"using NaiveNASlib.Advanced","category":"page"},{"location":"reference/advanced/graphquery/#NaiveNASlib.findterminating","page":"Advanced Graph Functions","title":"NaiveNASlib.findterminating","text":"findterminating(v::AbstractVertex, direction::Function, other::Function= v -> [], visited = [])\n\nReturn an array of all vertices which terminate size changes (i.e does not propagate them) seen through the given direction  (typically inputs or outputs). A vertex will be present once for each unique path through which its seen.\n\nThe other direction may be specified and will be traversed if a SizeInvariant vertex is encountered.\n\nWill return the given vertex if it is terminating.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Advanced\n\njulia> v1 = inputvertex(\"v1\", 3);\n\njulia> v2 = inputvertex(\"v2\", 3);\n\njulia> v3 = conc(v1,v2,v1,dims=1);\n\njulia> name.(findterminating(v1, outputs, inputs))\n1-element Vector{String}:\n \"v1\"\n\njulia> name.(findterminating(v3, outputs, inputs))\nAny[]\n\njulia> name.(findterminating(v3, inputs, outputs))\n3-element Vector{String}:\n \"v1\"\n \"v2\"\n \"v1\"\n\njulia> v5 = v3 + inputvertex(\"v4\", 9);\n\njulia> name.(findterminating(v3, outputs, inputs))\n1-element Vector{String}:\n \"v4\"\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/graphquery/#NaiveNASlib.all_in_graph","page":"Advanced Graph Functions","title":"NaiveNASlib.all_in_graph","text":"all_in_graph(v::AbstractVertex)\n\nReturn an array of vertices in the same graph (or connected component) as v\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/graphquery/#NaiveNASlib.output!","page":"Advanced Graph Functions","title":"NaiveNASlib.output!","text":"output!(memo::AbstractDict{K, V}, v::AbstractVertex) where {K,V}\n\nReturn the output from v given any input in memo by traversing the graph. Intermediate results from all visited vertices will be stored in memo after function exits.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Advanced, NaiveNASlib.Extend\n\njulia> ivs = InputVertex.(1:2);\n\njulia> v1 = CompVertex(*, ivs...);\n\njulia> v2 = CompVertex(-, v1, ivs[1]);\n\njulia> results = Dict{AbstractVertex, Any}(zip(ivs, [2,3]));\n\njulia> output!(results, v2)\n4\njulia> Pair{AbstractVertex, Int}[v=>results[v] for v in ancestors(v2)]\n4-element Vector{Pair{AbstractVertex, Int64}}:\n                                         InputVertex(1) => 2\n                                         InputVertex(2) => 3\n CompVertex(*, inputs=[InputVertex(1), InputVertex(2)]) => 6\n  CompVertex(-, inputs=[CompVertex(*), InputVertex(1)]) => 4\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/graphquery/#NaiveNASlib.ancestors","page":"Advanced Graph Functions","title":"NaiveNASlib.ancestors","text":"ancestors(v::AbstractVertex)\n\nReturn an array of all ancestors of v, including v itself.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Advanced, NaiveNASlib.Extend\n\njulia> ancestors(invariantvertex(+, inputvertex(\"in\", 1)))\n2-element Vector{AbstractVertex}:\n InputSizeVertex(InputVertex(in, outputs=[CompVertex(+)]), 1)\n MutationVertex(CompVertex(+, inputs=[in], outputs=[]), SizeInvariant())\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/graphquery/#NaiveNASlib.descendants","page":"Advanced Graph Functions","title":"NaiveNASlib.descendants","text":"descendants(v::AbstractVertex)\n\nReturn an array of all descendants of v, including v itself.\n\nExamples\n\njulia> using NaiveNASlib, NaiveNASlib.Advanced, NaiveNASlib.Extend\n\njulia> descendants(invariantvertex(+, inputvertex(\"in\", 1)) |> inputs |> first)\n2-element Vector{AbstractVertex}:\n MutationVertex(CompVertex(+, inputs=[in], outputs=[]), SizeInvariant())\n InputSizeVertex(InputVertex(in, outputs=[CompVertex(+)]), 1)\n\n\n\n\n\n","category":"function"},{"location":"reference/advanced/graphquery/#NaiveNASlib.defaultutility","page":"Advanced Graph Functions","title":"NaiveNASlib.defaultutility","text":"defaultutility(v::AbstractVertex)\n\nDefault function used to calculate utility of output neurons.\n\nImplement either defaultutility(f) or defaultutility(t, f) where f is the computation performed  by CompVertex and t is trait(v) to set the default for f. \n\nExamples\n\njulia> using NaiveNASlib, Statistics\n\njulia> struct Affine{T}\n        W::Matrix{T}\n       end;\n\njulia> NaiveNASlib.defaultutility(l::Affine) = mean(abs, l.W; dims=2);\n\njulia> NaiveNASlib.defaultutility(Affine(ones(2,3)))\n2×1 Matrix{Float64}:\n 1.0\n 1.0\n\n\n\n\n\n","category":"function"},{"location":"#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"NaiveNASlib provides a set of easy to use functions to modify the structure of a neural network, or more  generically, a computation graph. Apart from the obvious application in neural architecture search, this can also be useful in the context of transfer learning and structured pruning.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Main supported operations:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Change the number of neurons\nAdd vertices to the graph\nRemove vertices from the graph\nAdd edges to a vertex\nRemove edges to a vertex","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"For each of the above operations, NaiveNASlib makes the necessary changes to other vertices in the graph to ensure that it  is consistent w.r.t dimensions of the activations and so it to whatever extent possible represents the same function.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"While this is sometimes possible to do manually or through some ad-hoc method, things tend to explode in complexity for  more complex models. NaiveNASlib comes to the rescue so that you can focus on the actual problem. Any failure to produce a valid model after mutation warrants an issue!","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"NaiveNASlib makes few assumptions on the underlying implementation which in turn means that it is quite easy to make use of its capabilities for an existing library. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Note that there really isn't anything neural network specific about NaiveNASlib and it can be used to modify any computation graph. However, most its functionality is dead weight if there are not at least a handful of operations which require input to have a certain shape along some dimension. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The price one has to pay is that the model must be explicitly defined as a computation graph in the \"language\" of this library,  similar to what some older frameworks using less modern programming languages used to do. In its defense, the main reason anyone would use this library to begin with is to not have to create computation graphs themselves.","category":"page"},{"location":"#Reading-Guideline","page":"Introduction","title":"Reading Guideline","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The Quick Tutorial followed by the Advanced Tutorial are written to quickly introduce the ideas of NaiveNASlib and should serve as a good starting point to tell if this library might be useful to you. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The Terminology section is meant to clear things up if some recurring word or concept induces uncertainty but  should be entirely skippable otherwise.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The API reference is split up into the basic API which is the one introduced in the Quick Tutorial, the advanced API which is introduced in Advanced Tutorial and the API for extending NaiveNASlib. Each section is further split up into categories in an attempt to make it easy to answer \"how do I achieve X?\"-type questions.","category":"page"},{"location":"#Under-the-hood","page":"Introduction","title":"Under the hood","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"NaiveNASlib uses JuMP to describe not only the size relations, but also the connections between individual neurons as a Mixed Integer Linear Programming (MILP) problem. Describing neuron  relations with equality constraints turned out to give a nice declarative way of formulating the alignment problem and ensures that even deeply nested architectures stay aligned after mutation. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"While MILP problems are known for being quite difficult it seems like the abundance of equality constraints creates a quite tight formulation (don't quote me on this though :)) so that even when 10000s of neurons are involved the solution is produced in sub/few-second time. ","category":"page"}]
}
